{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:23:46.827278Z",
     "iopub.status.busy": "2023-11-21T01:23:46.827022Z",
     "iopub.status.idle": "2023-11-21T01:24:04.286480Z",
     "shell.execute_reply": "2023-11-21T01:24:04.285623Z",
     "shell.execute_reply.started": "2023-11-21T01:23:46.827254Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 16:42:37.393008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 21 16:42:49 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P4            Off  | 00000000:37:00.0 Off |                    0 |\r\n",
      "| N/A   28C    P8     6W /  75W |      0MiB /  7680MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import backend\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(fpath, label_key=\"labels\"):\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "\n",
    "    Args:\n",
    "        fpath: path the file to parse.\n",
    "        label_key: key for label data in the retrieve\n",
    "            dictionary.\n",
    "\n",
    "    Returns:\n",
    "        A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        d = cPickle.load(f, encoding=\"bytes\")\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode(\"utf8\")] = v\n",
    "        d = d_decoded\n",
    "    data = d[\"data\"]\n",
    "    labels = d[label_key]\n",
    "\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(label_mode=\"fine\"):\n",
    "    path = './cifar-100-python'\n",
    "\n",
    "    fpath = os.path.join(path, \"train\")\n",
    "    x_train, y_train = load_batch(fpath, label_key=label_mode + \"_labels\")\n",
    "\n",
    "    fpath = os.path.join(path, \"test\")\n",
    "    x_test, y_test = load_batch(fpath, label_key=label_mode + \"_labels\")\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "    if backend.image_data_format() == \"channels_last\":\n",
    "        x_train = x_train.transpose(0, 2, 3, 1)\n",
    "        x_test = x_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:24:50.355844Z",
     "iopub.status.busy": "2023-11-21T01:24:50.354792Z",
     "iopub.status.idle": "2023-11-21T01:24:56.079539Z",
     "shell.execute_reply": "2023-11-21T01:24:56.078730Z",
     "shell.execute_reply.started": "2023-11-21T01:24:50.355809Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train_val, y_train_val), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:24:59.032341Z",
     "iopub.status.busy": "2023-11-21T01:24:59.031600Z",
     "iopub.status.idle": "2023-11-21T01:24:59.039926Z",
     "shell.execute_reply": "2023-11-21T01:24:59.038736Z",
     "shell.execute_reply.started": "2023-11-21T01:24:59.032308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_val.shape, y_train_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:01.995440Z",
     "iopub.status.busy": "2023-11-21T01:25:01.995080Z",
     "iopub.status.idle": "2023-11-21T01:25:02.005737Z",
     "shell.execute_reply": "2023-11-21T01:25:02.004616Z",
     "shell.execute_reply.started": "2023-11-21T01:25:01.995409Z"
    }
   },
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "random_seed = 0\n",
    "num_train = x_train_val.shape[0]\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(val_size * num_train))\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "train_idx, val_idx = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:04.802527Z",
     "iopub.status.busy": "2023-11-21T01:25:04.802177Z",
     "iopub.status.idle": "2023-11-21T01:25:04.875391Z",
     "shell.execute_reply": "2023-11-21T01:25:04.874446Z",
     "shell.execute_reply.started": "2023-11-21T01:25:04.802498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val = x_train_val[train_idx], x_train_val[val_idx]\n",
    "y_train, y_val = y_train_val[train_idx], y_train_val[val_idx] \n",
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:27.690289Z",
     "iopub.status.busy": "2023-11-21T01:25:27.689762Z",
     "iopub.status.idle": "2023-11-21T01:25:27.704832Z",
     "shell.execute_reply": "2023-11-21T01:25:27.704071Z",
     "shell.execute_reply.started": "2023-11-21T01:25:27.690244Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import get_source_inputs\n",
    "from tensorflow.keras.layers import Activation, Add, Concatenate, Conv2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense\n",
    "from tensorflow.keras.layers import MaxPool2D, AveragePooling2D, BatchNormalization, Lambda, DepthwiseConv2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:30.628825Z",
     "iopub.status.busy": "2023-11-21T01:25:30.628461Z",
     "iopub.status.idle": "2023-11-21T01:25:30.649126Z",
     "shell.execute_reply": "2023-11-21T01:25:30.648158Z",
     "shell.execute_reply.started": "2023-11-21T01:25:30.628795Z"
    }
   },
   "outputs": [],
   "source": [
    "def channel_split(x, name=''):\n",
    "    # equipartition\n",
    "    in_channles = x.shape.as_list()[-1]\n",
    "    ip = in_channles // 2\n",
    "    c_hat = Lambda(lambda z: z[:, :, :, 0:ip], name='%s/sp%d_slice' % (name, 0))(x)\n",
    "    c = Lambda(lambda z: z[:, :, :, ip:], name='%s/sp%d_slice' % (name, 1))(x)\n",
    "    return c_hat, c\n",
    "\n",
    "def channel_shuffle(x):\n",
    "    height, width, channels = x.shape.as_list()[1:]\n",
    "    channels_per_split = channels // 2\n",
    "    x = K.reshape(x, (-1, height, width, 2, channels_per_split))\n",
    "    x = K.permute_dimensions(x, (0,1,2,4,3))\n",
    "    x = K.reshape(x, (-1, height, width, channels))\n",
    "    return x\n",
    "\n",
    "\n",
    "def shuffle_unit(inputs, out_channels, bottleneck_ratio,strides=2,stage=1,block=1):\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = -1\n",
    "    else:\n",
    "        raise ValueError('Only channels last supported')\n",
    "\n",
    "    prefix = 'stage{}/block{}'.format(stage, block)\n",
    "    bottleneck_channels = int(out_channels * bottleneck_ratio)\n",
    "    if strides < 2:\n",
    "        c_hat, c = channel_split(inputs, '{}/spl'.format(prefix))\n",
    "        inputs = c\n",
    "\n",
    "    x = Conv2D(bottleneck_channels, kernel_size=(1,1), strides=1, padding='same', name='{}/1x1conv_1'.format(prefix))(inputs)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_1'.format(prefix))(x)\n",
    "    x = Activation('relu', name='{}/relu_1x1conv_1'.format(prefix))(x)\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', name='{}/3x3dwconv'.format(prefix))(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv'.format(prefix))(x)\n",
    "    x = Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', name='{}/1x1conv_2'.format(prefix))(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_2'.format(prefix))(x)\n",
    "    x = Activation('relu', name='{}/relu_1x1conv_2'.format(prefix))(x)\n",
    "\n",
    "    if strides < 2:\n",
    "        ret = Concatenate(axis=bn_axis, name='{}/concat_1'.format(prefix))([x, c_hat])\n",
    "    else:\n",
    "        s2 = DepthwiseConv2D(kernel_size=3, strides=2, padding='same', name='{}/3x3dwconv_2'.format(prefix))(inputs)\n",
    "        s2 = BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv_2'.format(prefix))(s2)\n",
    "        s2 = Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', name='{}/1x1_conv_3'.format(prefix))(s2)\n",
    "        s2 = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_3'.format(prefix))(s2)\n",
    "        s2 = Activation('relu', name='{}/relu_1x1conv_3'.format(prefix))(s2)\n",
    "        ret = Concatenate(axis=bn_axis, name='{}/concat_2'.format(prefix))([x, s2])\n",
    "\n",
    "    ret = Lambda(channel_shuffle, name='{}/channel_shuffle'.format(prefix))(ret)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def block(x, channel_map, bottleneck_ratio, repeat=1, stage=1):\n",
    "    x = shuffle_unit(x, out_channels=channel_map[stage-1],\n",
    "                      strides=2,bottleneck_ratio=bottleneck_ratio,stage=stage,block=1)\n",
    "\n",
    "    for i in range(1, repeat+1):\n",
    "        x = shuffle_unit(x, out_channels=channel_map[stage-1],strides=1,\n",
    "                          bottleneck_ratio=bottleneck_ratio,stage=stage, block=(1+i))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:34.563376Z",
     "iopub.status.busy": "2023-11-21T01:25:34.562482Z",
     "iopub.status.idle": "2023-11-21T01:25:34.568704Z",
     "shell.execute_reply": "2023-11-21T01:25:34.567752Z",
     "shell.execute_reply.started": "2023-11-21T01:25:34.563334Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_augmentation_layer():\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.1),\n",
    "    ])\n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:37.062960Z",
     "iopub.status.busy": "2023-11-21T01:25:37.062086Z",
     "iopub.status.idle": "2023-11-21T01:25:37.067568Z",
     "shell.execute_reply": "2023-11-21T01:25:37.066743Z",
     "shell.execute_reply.started": "2023-11-21T01:25:37.062915Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_preprocess_layer():\n",
    "    data_preprocessing = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.Resizing(224, 224),\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    ])\n",
    "    return data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:39.199321Z",
     "iopub.status.busy": "2023-11-21T01:43:39.198317Z",
     "iopub.status.idle": "2023-11-21T01:43:39.215574Z",
     "shell.execute_reply": "2023-11-21T01:43:39.214765Z",
     "shell.execute_reply.started": "2023-11-21T01:43:39.199285Z"
    }
   },
   "outputs": [],
   "source": [
    "def ShuffleNetV2(include_top=True,\n",
    "                 input_tensor=None,\n",
    "                 scale_factor=1.0,\n",
    "                 pooling='max',\n",
    "                 input_shape=(224,224,3),\n",
    "                 load_model=None,\n",
    "                 num_shuffle_units=[3,7,3],\n",
    "                 bottleneck_ratio=1,\n",
    "                 classes=1000,\n",
    "                 augment=False,\n",
    "                 dropout=False,\n",
    "                 L1=False,\n",
    "                 L2=False):\n",
    "    if K.backend() != 'tensorflow':\n",
    "        raise RuntimeError('Only tensorflow supported for now')\n",
    "    name = 'ShuffleNetV2_{}_{}_{}'.format(scale_factor, bottleneck_ratio, \"\".join([str(x) for x in num_shuffle_units]))\n",
    "    out_dim_stage_two = {0.5:48, 1:116, 1.5:176, 2:244}\n",
    "\n",
    "    if pooling not in ['max', 'avg']:\n",
    "        raise ValueError('Invalid value for pooling')\n",
    "    if not (float(scale_factor)*4).is_integer():\n",
    "        raise ValueError('Invalid value for scale_factor, should be x over 4')\n",
    "    exp = np.insert(np.arange(len(num_shuffle_units), dtype=np.float32), 0, 0)  # [0., 0., 1., 2.]\n",
    "    out_channels_in_stage = 2**exp\n",
    "    out_channels_in_stage *= out_dim_stage_two[bottleneck_ratio]  #  calculate output channels for each stage\n",
    "    out_channels_in_stage[0] = 24  # first stage has always 24 output channels\n",
    "    out_channels_in_stage *= scale_factor\n",
    "    out_channels_in_stage = out_channels_in_stage.astype(int)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    \n",
    "    # data preprocessing\n",
    "    x = create_preprocess_layer()(img_input)\n",
    "    \n",
    "    # data augmentation\n",
    "    if augment:\n",
    "        x = create_augmentation_layer()(x)\n",
    "\n",
    "    # create shufflenet architecture\n",
    "    x = Conv2D(filters=out_channels_in_stage[0], kernel_size=(3, 3), padding='same', use_bias=False, strides=(2, 2),\n",
    "               activation='relu', name='conv1')(x)\n",
    "    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='maxpool1')(x)\n",
    "\n",
    "    # create stages containing shufflenet units beginning at stage 2\n",
    "    for stage in range(len(num_shuffle_units)):\n",
    "        repeat = num_shuffle_units[stage]\n",
    "        x = block(x, out_channels_in_stage,\n",
    "                   repeat=repeat,\n",
    "                   bottleneck_ratio=bottleneck_ratio,\n",
    "                   stage=stage + 2)\n",
    "\n",
    "    if bottleneck_ratio < 2:\n",
    "        k = 1024\n",
    "    else:\n",
    "        k = 2048\n",
    "    x = Conv2D(k, kernel_size=1, padding='same', strides=1, name='1x1conv5_out', activation='relu')(x)\n",
    "\n",
    "    if pooling == 'avg':\n",
    "        x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = GlobalMaxPooling2D(name='global_max_pool')(x)\n",
    "        \n",
    "    if dropout:\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    if include_top:\n",
    "        if L1:\n",
    "            x = Dense(classes, name='fc', kernel_regularizer='l1')(x)\n",
    "        elif L2:\n",
    "            x = Dense(classes, name='fc', kernel_regularizer='l2')(x)\n",
    "        else:\n",
    "            x = Dense(classes, name='fc')(x)\n",
    "        x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    if input_tensor:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    model = Model(inputs, x, name=name)\n",
    "\n",
    "    if load_model:\n",
    "        model.load_weights('', by_name=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:42.285699Z",
     "iopub.status.busy": "2023-11-21T01:43:42.285323Z",
     "iopub.status.idle": "2023-11-21T01:43:44.280038Z",
     "shell.execute_reply": "2023-11-21T01:43:44.278958Z",
     "shell.execute_reply.started": "2023-11-21T01:43:42.285656Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 16:43:49.603853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-11-21 16:43:49.626171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:37:00.0 name: Tesla P4 computeCapability: 6.1\n",
      "coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2023-11-21 16:43:49.626210: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-21 16:43:49.651497: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-21 16:43:49.664803: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-21 16:43:49.669197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-21 16:43:49.694242: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-21 16:43:49.700301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-21 16:43:49.750834: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-21 16:43:49.751718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-21 16:43:49.752161: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 16:43:49.763915: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600000000 Hz\n",
      "2023-11-21 16:43:49.765530: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x858b5a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-21 16:43:49.765548: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-21 16:43:49.855410: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x85a7130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-21 16:43:49.855445: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
      "2023-11-21 16:43:49.856685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:37:00.0 name: Tesla P4 computeCapability: 6.1\n",
      "coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2023-11-21 16:43:49.856720: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-21 16:43:49.856744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-21 16:43:49.856755: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-21 16:43:49.856766: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-21 16:43:49.856776: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-21 16:43:49.856786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-21 16:43:49.856798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-21 16:43:49.857234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-21 16:43:49.858086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-21 16:43:50.686246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-21 16:43:50.686281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-11-21 16:43:50.686289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-11-21 16:43:50.687978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6951 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:37:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ShuffleNetV2_1.0_1_373\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 224, 224, 3)  0           sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 24) 648         sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 56, 56, 24)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1conv_1 (Conv2D (None, 56, 56, 116)  2900        maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_1 (Bat (None, 56, 56, 116)  464         stage2/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_1 (A (None, 56, 56, 116)  0           stage2/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/3x3dwconv_2 (Dept (None, 28, 28, 24)   240         maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_3x3dwconv_2 (B (None, 28, 28, 24)   96          stage2/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1_conv_3 (Conv2 (None, 28, 28, 116)  2900        stage2/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_3 (Bat (None, 28, 28, 116)  464         stage2/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_3 (A (None, 28, 28, 116)  0           stage2/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/concat_2 (Concate (None, 28, 28, 232)  0           stage2/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1conv_1 (Conv2D (None, 28, 28, 232)  54056       stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_1 (Bat (None, 28, 28, 232)  928         stage3/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_1 (A (None, 28, 28, 232)  0           stage3/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/3x3dwconv_2 (Dept (None, 14, 14, 232)  2320        stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_3x3dwconv_2 (B (None, 14, 14, 232)  928         stage3/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1_conv_3 (Conv2 (None, 14, 14, 232)  54056       stage3/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_3 (Bat (None, 14, 14, 232)  928         stage3/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_3 (A (None, 14, 14, 232)  0           stage3/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/concat_2 (Concate (None, 14, 14, 464)  0           stage3/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block5/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block5/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block5/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block5/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block5/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block5/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block5/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block5/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block5/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block5/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block5/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block6/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block6/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block6/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block6/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block6/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block6/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block6/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block6/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block6/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block6/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block6/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block7/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block7/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block7/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block7/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block7/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block7/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block7/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block7/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block7/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block7/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block7/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block8/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block8/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block8/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block8/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block8/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block8/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block8/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block8/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block8/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block8/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block8/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1conv_1 (Conv2D (None, 14, 14, 464)  215760      stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_1 (Bat (None, 14, 14, 464)  1856        stage4/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_1 (A (None, 14, 14, 464)  0           stage4/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/3x3dwconv_2 (Dept (None, 7, 7, 464)    4640        stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_3x3dwconv_2 (B (None, 7, 7, 464)    1856        stage4/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_conv_3 (Conv2 (None, 7, 7, 464)    215760      stage4/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_3 (Bat (None, 7, 7, 464)    1856        stage4/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_3 (A (None, 7, 7, 464)    0           stage4/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/concat_2 (Concate (None, 7, 7, 928)    0           stage4/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "1x1conv5_out (Conv2D)           (None, 7, 7, 1024)   951296      stage4/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (GlobalMaxPooli (None, 1024)         0           1x1conv5_out[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 100)          102500      global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 100)          0           fc[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 4,121,240\n",
      "Trainable params: 4,093,120\n",
      "Non-trainable params: 28,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ShuffleNetV2(include_top=True, input_shape=(32, 32, 3), bottleneck_ratio=1, classes=100, augment=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:26:30.410929Z",
     "iopub.status.busy": "2023-11-21T01:26:30.410201Z",
     "iopub.status.idle": "2023-11-21T01:26:30.415945Z",
     "shell.execute_reply": "2023-11-21T01:26:30.415085Z",
     "shell.execute_reply.started": "2023-11-21T01:26:30.410893Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:26:33.941227Z",
     "iopub.status.busy": "2023-11-21T01:26:33.940555Z",
     "iopub.status.idle": "2023-11-21T01:26:33.945532Z",
     "shell.execute_reply": "2023-11-21T01:26:33.944739Z",
     "shell.execute_reply.started": "2023-11-21T01:26:33.941193Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_name = './data_augmentation'\n",
    "os.makedirs(exp_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:59.371765Z",
     "iopub.status.busy": "2023-11-21T01:43:59.371372Z",
     "iopub.status.idle": "2023-11-21T01:43:59.391446Z",
     "shell.execute_reply": "2023-11-21T01:43:59.390657Z",
     "shell.execute_reply.started": "2023-11-21T01:43:59.371732Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "num_epochs = 100\n",
    "optim = \"adam\"\n",
    "mcp_save = ModelCheckpoint(f'{exp_name}/shufflenetv2_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "rlronp = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, min_lr=0.000001)\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optim,\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:44:03.271135Z",
     "iopub.status.busy": "2023-11-21T01:44:03.270215Z",
     "iopub.status.idle": "2023-11-21T02:53:38.174170Z",
     "shell.execute_reply": "2023-11-21T02:53:38.172596Z",
     "shell.execute_reply.started": "2023-11-21T01:44:03.271099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 16:44:28.978509: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-21 16:44:29.281404: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 225s 359ms/step - loss: 4.1926 - sparse_categorical_accuracy: 0.0681 - val_loss: 4.6270 - val_sparse_categorical_accuracy: 0.0266\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 3.6351 - sparse_categorical_accuracy: 0.1415 - val_loss: 3.6438 - val_sparse_categorical_accuracy: 0.1422\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 3.3453 - sparse_categorical_accuracy: 0.1906 - val_loss: 3.4244 - val_sparse_categorical_accuracy: 0.1866\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 3.1549 - sparse_categorical_accuracy: 0.2232 - val_loss: 3.1392 - val_sparse_categorical_accuracy: 0.2374\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 3.0063 - sparse_categorical_accuracy: 0.2521 - val_loss: 3.0702 - val_sparse_categorical_accuracy: 0.2410\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 2.8531 - sparse_categorical_accuracy: 0.2817 - val_loss: 2.8751 - val_sparse_categorical_accuracy: 0.2784\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 2.7269 - sparse_categorical_accuracy: 0.3049 - val_loss: 2.8326 - val_sparse_categorical_accuracy: 0.2921\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 2.5912 - sparse_categorical_accuracy: 0.3343 - val_loss: 2.7213 - val_sparse_categorical_accuracy: 0.3188\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 2.4793 - sparse_categorical_accuracy: 0.3553 - val_loss: 2.5963 - val_sparse_categorical_accuracy: 0.3417\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 2.3708 - sparse_categorical_accuracy: 0.3803 - val_loss: 2.4806 - val_sparse_categorical_accuracy: 0.3634\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 2.2613 - sparse_categorical_accuracy: 0.4049 - val_loss: 2.4769 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 2.1807 - sparse_categorical_accuracy: 0.4216 - val_loss: 2.4688 - val_sparse_categorical_accuracy: 0.3823\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 2.1012 - sparse_categorical_accuracy: 0.4382 - val_loss: 2.3343 - val_sparse_categorical_accuracy: 0.3985\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 2.0278 - sparse_categorical_accuracy: 0.4560 - val_loss: 2.2621 - val_sparse_categorical_accuracy: 0.4151\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 1.9629 - sparse_categorical_accuracy: 0.4684 - val_loss: 2.2140 - val_sparse_categorical_accuracy: 0.4251\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 1.8919 - sparse_categorical_accuracy: 0.4856 - val_loss: 2.0560 - val_sparse_categorical_accuracy: 0.4616\n",
      "Epoch 17/100\n",
      "478/625 [=====================>........] - ETA: 49s - loss: 1.8367 - sparse_categorical_accuracy: 0.4959"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 224s 359ms/step - loss: 0.8555 - sparse_categorical_accuracy: 0.7438 - val_loss: 1.5520 - val_sparse_categorical_accuracy: 0.6003\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.8292 - sparse_categorical_accuracy: 0.7523 - val_loss: 1.5609 - val_sparse_categorical_accuracy: 0.5994\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.8320 - sparse_categorical_accuracy: 0.7513\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.8320 - sparse_categorical_accuracy: 0.7513 - val_loss: 1.5839 - val_sparse_categorical_accuracy: 0.5960\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7974 - sparse_categorical_accuracy: 0.7613 - val_loss: 1.5584 - val_sparse_categorical_accuracy: 0.5976\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7863 - sparse_categorical_accuracy: 0.7668\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7863 - sparse_categorical_accuracy: 0.7668 - val_loss: 1.5642 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 41/100\n",
      "429/625 [===================>..........] - ETA: 1:05 - loss: 0.7697 - sparse_categorical_accuracy: 0.7708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - ETA: 0s - loss: 0.7467 - sparse_categorical_accuracy: 0.7770\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7467 - sparse_categorical_accuracy: 0.7770 - val_loss: 1.5603 - val_sparse_categorical_accuracy: 0.6033\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7477 - sparse_categorical_accuracy: 0.7739 - val_loss: 1.5609 - val_sparse_categorical_accuracy: 0.6035\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7510 - sparse_categorical_accuracy: 0.7752\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7510 - sparse_categorical_accuracy: 0.7752 - val_loss: 1.5607 - val_sparse_categorical_accuracy: 0.6046\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7430 - sparse_categorical_accuracy: 0.7781 - val_loss: 1.5580 - val_sparse_categorical_accuracy: 0.6049\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7426 - sparse_categorical_accuracy: 0.7772 - val_loss: 1.5609 - val_sparse_categorical_accuracy: 0.6045\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7487 - sparse_categorical_accuracy: 0.7754 - val_loss: 1.5620 - val_sparse_categorical_accuracy: 0.6036\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7497 - sparse_categorical_accuracy: 0.7750 - val_loss: 1.5601 - val_sparse_categorical_accuracy: 0.6044\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7436 - sparse_categorical_accuracy: 0.7788 - val_loss: 1.5621 - val_sparse_categorical_accuracy: 0.6041\n",
      "Epoch 56/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7467 - sparse_categorical_accuracy: 0.7786 - val_loss: 1.5606 - val_sparse_categorical_accuracy: 0.6045\n",
      "Epoch 57/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7474 - sparse_categorical_accuracy: 0.7756 - val_loss: 1.5598 - val_sparse_categorical_accuracy: 0.6053\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7507 - sparse_categorical_accuracy: 0.7742 - val_loss: 1.5596 - val_sparse_categorical_accuracy: 0.6050\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7412 - sparse_categorical_accuracy: 0.7779 - val_loss: 1.5593 - val_sparse_categorical_accuracy: 0.6034\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7445 - sparse_categorical_accuracy: 0.7772 - val_loss: 1.5593 - val_sparse_categorical_accuracy: 0.6051\n",
      "Epoch 61/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7552 - sparse_categorical_accuracy: 0.7720 - val_loss: 1.5585 - val_sparse_categorical_accuracy: 0.6044\n",
      "Epoch 62/100\n",
      "109/625 [====>.........................] - ETA: 2:52 - loss: 0.7563 - sparse_categorical_accuracy: 0.7722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7446 - sparse_categorical_accuracy: 0.7771 - val_loss: 1.5602 - val_sparse_categorical_accuracy: 0.6042\n",
      "Epoch 72/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7447 - sparse_categorical_accuracy: 0.7772 - val_loss: 1.5621 - val_sparse_categorical_accuracy: 0.6041\n",
      "Epoch 73/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7425 - sparse_categorical_accuracy: 0.7778 - val_loss: 1.5615 - val_sparse_categorical_accuracy: 0.6045\n",
      "Epoch 74/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7472 - sparse_categorical_accuracy: 0.7748 - val_loss: 1.5611 - val_sparse_categorical_accuracy: 0.6045\n",
      "Epoch 75/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7459 - sparse_categorical_accuracy: 0.7775 - val_loss: 1.5599 - val_sparse_categorical_accuracy: 0.6041\n",
      "Epoch 76/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7391 - sparse_categorical_accuracy: 0.7789 - val_loss: 1.5623 - val_sparse_categorical_accuracy: 0.6050\n",
      "Epoch 77/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7398 - sparse_categorical_accuracy: 0.7792 - val_loss: 1.5613 - val_sparse_categorical_accuracy: 0.6048\n",
      "Epoch 78/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7432 - sparse_categorical_accuracy: 0.7772 - val_loss: 1.5604 - val_sparse_categorical_accuracy: 0.6054\n",
      "Epoch 79/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7438 - sparse_categorical_accuracy: 0.7778 - val_loss: 1.5600 - val_sparse_categorical_accuracy: 0.6062\n",
      "Epoch 80/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7415 - sparse_categorical_accuracy: 0.7773 - val_loss: 1.5617 - val_sparse_categorical_accuracy: 0.6041\n",
      "Epoch 81/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7443 - sparse_categorical_accuracy: 0.7774 - val_loss: 1.5619 - val_sparse_categorical_accuracy: 0.6054\n",
      "Epoch 82/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7403 - sparse_categorical_accuracy: 0.7778 - val_loss: 1.5598 - val_sparse_categorical_accuracy: 0.6038\n",
      "Epoch 83/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7434 - sparse_categorical_accuracy: 0.7773 - val_loss: 1.5597 - val_sparse_categorical_accuracy: 0.6043\n",
      "Epoch 84/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7428 - sparse_categorical_accuracy: 0.7775 - val_loss: 1.5638 - val_sparse_categorical_accuracy: 0.6049\n",
      "Epoch 85/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7467 - sparse_categorical_accuracy: 0.7778 - val_loss: 1.5615 - val_sparse_categorical_accuracy: 0.6037\n",
      "Epoch 86/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7422 - sparse_categorical_accuracy: 0.7785 - val_loss: 1.5633 - val_sparse_categorical_accuracy: 0.6045\n",
      "Epoch 87/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7360 - sparse_categorical_accuracy: 0.7769 - val_loss: 1.5619 - val_sparse_categorical_accuracy: 0.6048\n",
      "Epoch 88/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7418 - sparse_categorical_accuracy: 0.7760 - val_loss: 1.5611 - val_sparse_categorical_accuracy: 0.6055\n",
      "Epoch 89/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7395 - sparse_categorical_accuracy: 0.7779 - val_loss: 1.5586 - val_sparse_categorical_accuracy: 0.6053\n",
      "Epoch 90/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7386 - sparse_categorical_accuracy: 0.7791 - val_loss: 1.5618 - val_sparse_categorical_accuracy: 0.6055\n",
      "Epoch 91/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7376 - sparse_categorical_accuracy: 0.7787 - val_loss: 1.5619 - val_sparse_categorical_accuracy: 0.6056\n",
      "Epoch 92/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7403 - sparse_categorical_accuracy: 0.7782 - val_loss: 1.5611 - val_sparse_categorical_accuracy: 0.6053\n",
      "Epoch 93/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7402 - sparse_categorical_accuracy: 0.7796 - val_loss: 1.5602 - val_sparse_categorical_accuracy: 0.6061\n",
      "Epoch 94/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7388 - sparse_categorical_accuracy: 0.7794 - val_loss: 1.5586 - val_sparse_categorical_accuracy: 0.6051\n",
      "Epoch 95/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7390 - sparse_categorical_accuracy: 0.7814 - val_loss: 1.5590 - val_sparse_categorical_accuracy: 0.6043\n",
      "Epoch 96/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7400 - sparse_categorical_accuracy: 0.7779 - val_loss: 1.5615 - val_sparse_categorical_accuracy: 0.6062\n",
      "Epoch 97/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7357 - sparse_categorical_accuracy: 0.7796 - val_loss: 1.5609 - val_sparse_categorical_accuracy: 0.6052\n",
      "Epoch 98/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7350 - sparse_categorical_accuracy: 0.7789 - val_loss: 1.5609 - val_sparse_categorical_accuracy: 0.6059\n",
      "Epoch 99/100\n",
      "625/625 [==============================] - 224s 359ms/step - loss: 0.7402 - sparse_categorical_accuracy: 0.7783 - val_loss: 1.5601 - val_sparse_categorical_accuracy: 0.6050\n",
      "Epoch 100/100\n",
      "625/625 [==============================] - 224s 358ms/step - loss: 0.7378 - sparse_categorical_accuracy: 0.7786 - val_loss: 1.5617 - val_sparse_categorical_accuracy: 0.6046\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    x=x_train,y=y_train,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val,y_val),\n",
    "    verbose=1,\n",
    "    callbacks=[mcp_save,rlronp],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['sparse_categorical_accuracy']\n",
    "val_acc=hist.history['val_sparse_categorical_accuracy']\n",
    "np.savez(os.path.join(exp_name, 'fit_history.npz'), train_loss=train_loss, val_loss=val_loss, train_acc=train_acc, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T03:01:35.270419Z",
     "iopub.status.busy": "2023-11-21T03:01:35.270058Z",
     "iopub.status.idle": "2023-11-21T03:01:35.277235Z",
     "shell.execute_reply": "2023-11-21T03:01:35.276344Z",
     "shell.execute_reply.started": "2023-11-21T03:01:35.270388Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss=model.history.history['loss']\n",
    "val_loss=model.history.history['val_loss']\n",
    "train_acc=model.history.history['sparse_categorical_accuracy']\n",
    "val_acc=model.history.history['val_sparse_categorical_accuracy']\n",
    "np.savez(os.path.join(exp_name, 'fit_history.npz'), train_loss=train_loss, val_loss=val_loss, train_acc=train_acc, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:53:58.007978Z",
     "iopub.status.busy": "2023-11-21T02:53:58.007409Z",
     "iopub.status.idle": "2023-11-21T02:55:11.103478Z",
     "shell.execute_reply": "2023-11-21T02:55:11.102729Z",
     "shell.execute_reply.started": "2023-11-21T02:53:58.007942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 51s 5ms/step - loss: 1.5012 - sparse_categorical_accuracy: 0.6087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5012279748916626, 0.6086999773979187]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_model = f'{exp_name}/shufflenetv2_model.hdf5'\n",
    "loaded_model_from_hdf5 = tf.keras.models.load_model(hdf5_model)\n",
    "loaded_model_from_hdf5.evaluate(x_test,y_test,batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
