{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:23:46.827278Z",
     "iopub.status.busy": "2023-11-21T01:23:46.827022Z",
     "iopub.status.idle": "2023-11-21T01:24:04.286480Z",
     "shell.execute_reply": "2023-11-21T01:24:04.285623Z",
     "shell.execute_reply.started": "2023-11-21T01:23:46.827254Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 08:44:36.867778: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 23 08:44:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:12:00.0 Off |                    0 |\n",
      "| N/A   33C    P8    14W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import backend\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(fpath, label_key=\"labels\"):\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "\n",
    "    Args:\n",
    "        fpath: path the file to parse.\n",
    "        label_key: key for label data in the retrieve\n",
    "            dictionary.\n",
    "\n",
    "    Returns:\n",
    "        A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        d = cPickle.load(f, encoding=\"bytes\")\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode(\"utf8\")] = v\n",
    "        d = d_decoded\n",
    "    data = d[\"data\"]\n",
    "    labels = d[label_key]\n",
    "\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(label_mode=\"fine\"):\n",
    "    path = './cifar-100-python'\n",
    "\n",
    "    fpath = os.path.join(path, \"train\")\n",
    "    x_train, y_train = load_batch(fpath, label_key=label_mode + \"_labels\")\n",
    "\n",
    "    fpath = os.path.join(path, \"test\")\n",
    "    x_test, y_test = load_batch(fpath, label_key=label_mode + \"_labels\")\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "    if backend.image_data_format() == \"channels_last\":\n",
    "        x_train = x_train.transpose(0, 2, 3, 1)\n",
    "        x_test = x_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:24:50.355844Z",
     "iopub.status.busy": "2023-11-21T01:24:50.354792Z",
     "iopub.status.idle": "2023-11-21T01:24:56.079539Z",
     "shell.execute_reply": "2023-11-21T01:24:56.078730Z",
     "shell.execute_reply.started": "2023-11-21T01:24:50.355809Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train_val, y_train_val), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:24:59.032341Z",
     "iopub.status.busy": "2023-11-21T01:24:59.031600Z",
     "iopub.status.idle": "2023-11-21T01:24:59.039926Z",
     "shell.execute_reply": "2023-11-21T01:24:59.038736Z",
     "shell.execute_reply.started": "2023-11-21T01:24:59.032308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_val.shape, y_train_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:01.995440Z",
     "iopub.status.busy": "2023-11-21T01:25:01.995080Z",
     "iopub.status.idle": "2023-11-21T01:25:02.005737Z",
     "shell.execute_reply": "2023-11-21T01:25:02.004616Z",
     "shell.execute_reply.started": "2023-11-21T01:25:01.995409Z"
    }
   },
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "random_seed = 0\n",
    "num_train = x_train_val.shape[0]\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(val_size * num_train))\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "train_idx, val_idx = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:04.802527Z",
     "iopub.status.busy": "2023-11-21T01:25:04.802177Z",
     "iopub.status.idle": "2023-11-21T01:25:04.875391Z",
     "shell.execute_reply": "2023-11-21T01:25:04.874446Z",
     "shell.execute_reply.started": "2023-11-21T01:25:04.802498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val = x_train_val[train_idx], x_train_val[val_idx]\n",
    "y_train, y_val = y_train_val[train_idx], y_train_val[val_idx] \n",
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:27.690289Z",
     "iopub.status.busy": "2023-11-21T01:25:27.689762Z",
     "iopub.status.idle": "2023-11-21T01:25:27.704832Z",
     "shell.execute_reply": "2023-11-21T01:25:27.704071Z",
     "shell.execute_reply.started": "2023-11-21T01:25:27.690244Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import get_source_inputs\n",
    "from tensorflow.keras.layers import Activation, Add, Concatenate, Conv2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense\n",
    "from tensorflow.keras.layers import MaxPool2D, AveragePooling2D, BatchNormalization, Lambda, DepthwiseConv2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:30.628825Z",
     "iopub.status.busy": "2023-11-21T01:25:30.628461Z",
     "iopub.status.idle": "2023-11-21T01:25:30.649126Z",
     "shell.execute_reply": "2023-11-21T01:25:30.648158Z",
     "shell.execute_reply.started": "2023-11-21T01:25:30.628795Z"
    }
   },
   "outputs": [],
   "source": [
    "def channel_split(x, name=''):\n",
    "    # equipartition\n",
    "    in_channles = x.shape.as_list()[-1]\n",
    "    ip = in_channles // 2\n",
    "    c_hat = Lambda(lambda z: z[:, :, :, 0:ip], name='%s/sp%d_slice' % (name, 0))(x)\n",
    "    c = Lambda(lambda z: z[:, :, :, ip:], name='%s/sp%d_slice' % (name, 1))(x)\n",
    "    return c_hat, c\n",
    "\n",
    "def channel_shuffle(x):\n",
    "    height, width, channels = x.shape.as_list()[1:]\n",
    "    channels_per_split = channels // 2\n",
    "    x = K.reshape(x, (-1, height, width, 2, channels_per_split))\n",
    "    x = K.permute_dimensions(x, (0,1,2,4,3))\n",
    "    x = K.reshape(x, (-1, height, width, channels))\n",
    "    return x\n",
    "\n",
    "\n",
    "def shuffle_unit(inputs, out_channels, bottleneck_ratio,strides=2,stage=1,block=1):\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = -1\n",
    "    else:\n",
    "        raise ValueError('Only channels last supported')\n",
    "\n",
    "    prefix = 'stage{}/block{}'.format(stage, block)\n",
    "    bottleneck_channels = int(out_channels * bottleneck_ratio)\n",
    "    if strides < 2:\n",
    "        c_hat, c = channel_split(inputs, '{}/spl'.format(prefix))\n",
    "        inputs = c\n",
    "\n",
    "    x = Conv2D(bottleneck_channels, kernel_size=(1,1), strides=1, padding='same', name='{}/1x1conv_1'.format(prefix))(inputs)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_1'.format(prefix))(x)\n",
    "    x = Activation('relu', name='{}/relu_1x1conv_1'.format(prefix))(x)\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', name='{}/3x3dwconv'.format(prefix))(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv'.format(prefix))(x)\n",
    "    x = Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', name='{}/1x1conv_2'.format(prefix))(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_2'.format(prefix))(x)\n",
    "    x = Activation('relu', name='{}/relu_1x1conv_2'.format(prefix))(x)\n",
    "\n",
    "    if strides < 2:\n",
    "        ret = Concatenate(axis=bn_axis, name='{}/concat_1'.format(prefix))([x, c_hat])\n",
    "    else:\n",
    "        s2 = DepthwiseConv2D(kernel_size=3, strides=2, padding='same', name='{}/3x3dwconv_2'.format(prefix))(inputs)\n",
    "        s2 = BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv_2'.format(prefix))(s2)\n",
    "        s2 = Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', name='{}/1x1_conv_3'.format(prefix))(s2)\n",
    "        s2 = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_3'.format(prefix))(s2)\n",
    "        s2 = Activation('relu', name='{}/relu_1x1conv_3'.format(prefix))(s2)\n",
    "        ret = Concatenate(axis=bn_axis, name='{}/concat_2'.format(prefix))([x, s2])\n",
    "\n",
    "    ret = Lambda(channel_shuffle, name='{}/channel_shuffle'.format(prefix))(ret)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def block(x, channel_map, bottleneck_ratio, repeat=1, stage=1):\n",
    "    x = shuffle_unit(x, out_channels=channel_map[stage-1],\n",
    "                      strides=2,bottleneck_ratio=bottleneck_ratio,stage=stage,block=1)\n",
    "\n",
    "    for i in range(1, repeat+1):\n",
    "        x = shuffle_unit(x, out_channels=channel_map[stage-1],strides=1,\n",
    "                          bottleneck_ratio=bottleneck_ratio,stage=stage, block=(1+i))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:34.563376Z",
     "iopub.status.busy": "2023-11-21T01:25:34.562482Z",
     "iopub.status.idle": "2023-11-21T01:25:34.568704Z",
     "shell.execute_reply": "2023-11-21T01:25:34.567752Z",
     "shell.execute_reply.started": "2023-11-21T01:25:34.563334Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_augmentation_layer():\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.1),\n",
    "    ])\n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:37.062960Z",
     "iopub.status.busy": "2023-11-21T01:25:37.062086Z",
     "iopub.status.idle": "2023-11-21T01:25:37.067568Z",
     "shell.execute_reply": "2023-11-21T01:25:37.066743Z",
     "shell.execute_reply.started": "2023-11-21T01:25:37.062915Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_preprocess_layer():\n",
    "    data_preprocessing = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.Resizing(224, 224),\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    ])\n",
    "    return data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:39.199321Z",
     "iopub.status.busy": "2023-11-21T01:43:39.198317Z",
     "iopub.status.idle": "2023-11-21T01:43:39.215574Z",
     "shell.execute_reply": "2023-11-21T01:43:39.214765Z",
     "shell.execute_reply.started": "2023-11-21T01:43:39.199285Z"
    }
   },
   "outputs": [],
   "source": [
    "def ShuffleNetV2(include_top=True,\n",
    "                 input_tensor=None,\n",
    "                 scale_factor=1.0,\n",
    "                 pooling='max',\n",
    "                 input_shape=(224,224,3),\n",
    "                 load_model=None,\n",
    "                 num_shuffle_units=[3,7,3],\n",
    "                 bottleneck_ratio=1,\n",
    "                 classes=1000,\n",
    "                 augment=False,\n",
    "                 dropout=False,\n",
    "                 L1=False,\n",
    "                 L2=False):\n",
    "    if K.backend() != 'tensorflow':\n",
    "        raise RuntimeError('Only tensorflow supported for now')\n",
    "    name = 'ShuffleNetV2_{}_{}_{}'.format(scale_factor, bottleneck_ratio, \"\".join([str(x) for x in num_shuffle_units]))\n",
    "    out_dim_stage_two = {0.5:48, 1:116, 1.5:176, 2:244}\n",
    "\n",
    "    if pooling not in ['max', 'avg']:\n",
    "        raise ValueError('Invalid value for pooling')\n",
    "    if not (float(scale_factor)*4).is_integer():\n",
    "        raise ValueError('Invalid value for scale_factor, should be x over 4')\n",
    "    exp = np.insert(np.arange(len(num_shuffle_units), dtype=np.float32), 0, 0)  # [0., 0., 1., 2.]\n",
    "    out_channels_in_stage = 2**exp\n",
    "    out_channels_in_stage *= out_dim_stage_two[bottleneck_ratio]  #  calculate output channels for each stage\n",
    "    out_channels_in_stage[0] = 24  # first stage has always 24 output channels\n",
    "    out_channels_in_stage *= scale_factor\n",
    "    out_channels_in_stage = out_channels_in_stage.astype(int)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    \n",
    "    # data preprocessing\n",
    "    x = create_preprocess_layer()(img_input)\n",
    "    \n",
    "    # data augmentation\n",
    "    if augment:\n",
    "        x = create_augmentation_layer()(x)\n",
    "\n",
    "    # create shufflenet architecture\n",
    "    x = Conv2D(filters=out_channels_in_stage[0], kernel_size=(3, 3), padding='same', use_bias=False, strides=(2, 2),\n",
    "               activation='relu', name='conv1')(x)\n",
    "    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='maxpool1')(x)\n",
    "\n",
    "    # create stages containing shufflenet units beginning at stage 2\n",
    "    for stage in range(len(num_shuffle_units)):\n",
    "        repeat = num_shuffle_units[stage]\n",
    "        x = block(x, out_channels_in_stage,\n",
    "                   repeat=repeat,\n",
    "                   bottleneck_ratio=bottleneck_ratio,\n",
    "                   stage=stage + 2)\n",
    "\n",
    "    if bottleneck_ratio < 2:\n",
    "        k = 1024\n",
    "    else:\n",
    "        k = 2048\n",
    "    x = Conv2D(k, kernel_size=1, padding='same', strides=1, name='1x1conv5_out', activation='relu')(x)\n",
    "\n",
    "    if pooling == 'avg':\n",
    "        x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = GlobalMaxPooling2D(name='global_max_pool')(x)\n",
    "        \n",
    "    if dropout:\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    if include_top:\n",
    "        if L1:\n",
    "            x = Dense(classes, name='fc', kernel_regularizer=tf.keras.regularizers.l1(0.001))(x)\n",
    "        elif L2:\n",
    "            x = Dense(classes, name='fc', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "        else:\n",
    "            x = Dense(classes, name='fc')(x)\n",
    "        x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    if input_tensor:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    model = Model(inputs, x, name=name)\n",
    "\n",
    "    if load_model:\n",
    "        model.load_weights('', by_name=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:42.285699Z",
     "iopub.status.busy": "2023-11-21T01:43:42.285323Z",
     "iopub.status.idle": "2023-11-21T01:43:44.280038Z",
     "shell.execute_reply": "2023-11-21T01:43:44.278958Z",
     "shell.execute_reply.started": "2023-11-21T01:43:42.285656Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 00:06:55.745081: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-11-23 00:06:55.906243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:12:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-11-23 00:06:55.906278: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-23 00:06:56.049994: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-23 00:06:56.084249: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-23 00:06:56.104215: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-23 00:06:56.198953: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-23 00:06:56.236753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-23 00:06:56.424994: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-23 00:06:56.428502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-23 00:06:56.428963: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-23 00:06:56.440456: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2700000000 Hz\n",
      "2023-11-23 00:06:56.441992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8109530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-23 00:06:56.442010: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-23 00:06:56.628298: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8125080 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-23 00:06:56.628330: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-11-23 00:06:56.632139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:12:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-11-23 00:06:56.632172: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-23 00:06:56.632195: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-23 00:06:56.632204: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-23 00:06:56.632213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-23 00:06:56.632222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-23 00:06:56.632230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-23 00:06:56.632239: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-23 00:06:56.634807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-23 00:06:56.638008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-23 00:06:58.358776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-23 00:06:58.358808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-11-23 00:06:58.358815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-11-23 00:06:58.363377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13784 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:12:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ShuffleNetV2_1.0_1_373\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 24) 648         sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 56, 56, 24)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1conv_1 (Conv2D (None, 56, 56, 116)  2900        maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_1 (Bat (None, 56, 56, 116)  464         stage2/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_1 (A (None, 56, 56, 116)  0           stage2/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/3x3dwconv_2 (Dept (None, 28, 28, 24)   240         maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_3x3dwconv_2 (B (None, 28, 28, 24)   96          stage2/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1_conv_3 (Conv2 (None, 28, 28, 116)  2900        stage2/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_3 (Bat (None, 28, 28, 116)  464         stage2/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_3 (A (None, 28, 28, 116)  0           stage2/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/concat_2 (Concate (None, 28, 28, 232)  0           stage2/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1conv_1 (Conv2D (None, 28, 28, 232)  54056       stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_1 (Bat (None, 28, 28, 232)  928         stage3/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_1 (A (None, 28, 28, 232)  0           stage3/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/3x3dwconv_2 (Dept (None, 14, 14, 232)  2320        stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_3x3dwconv_2 (B (None, 14, 14, 232)  928         stage3/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1_conv_3 (Conv2 (None, 14, 14, 232)  54056       stage3/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_3 (Bat (None, 14, 14, 232)  928         stage3/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_3 (A (None, 14, 14, 232)  0           stage3/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/concat_2 (Concate (None, 14, 14, 464)  0           stage3/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block5/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block5/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block5/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block5/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block5/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block5/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block5/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block5/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block5/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block5/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block5/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block6/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block6/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block6/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block6/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block6/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block6/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block6/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block6/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block6/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block6/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block6/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block7/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block7/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block7/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block7/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block7/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block7/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block7/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block7/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block7/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block7/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block7/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block8/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block8/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block8/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block8/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block8/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block8/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block8/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block8/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block8/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block8/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block8/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1conv_1 (Conv2D (None, 14, 14, 464)  215760      stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_1 (Bat (None, 14, 14, 464)  1856        stage4/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_1 (A (None, 14, 14, 464)  0           stage4/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/3x3dwconv_2 (Dept (None, 7, 7, 464)    4640        stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_3x3dwconv_2 (B (None, 7, 7, 464)    1856        stage4/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_conv_3 (Conv2 (None, 7, 7, 464)    215760      stage4/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_3 (Bat (None, 7, 7, 464)    1856        stage4/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_3 (A (None, 7, 7, 464)    0           stage4/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/concat_2 (Concate (None, 7, 7, 928)    0           stage4/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "1x1conv5_out (Conv2D)           (None, 7, 7, 1024)   951296      stage4/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (GlobalMaxPooli (None, 1024)         0           1x1conv5_out[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 100)          102500      global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 100)          0           fc[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 4,121,240\n",
      "Trainable params: 4,093,120\n",
      "Non-trainable params: 28,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ShuffleNetV2(include_top=True, input_shape=(32, 32, 3), bottleneck_ratio=1, classes=100, L2=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:26:30.410929Z",
     "iopub.status.busy": "2023-11-21T01:26:30.410201Z",
     "iopub.status.idle": "2023-11-21T01:26:30.415945Z",
     "shell.execute_reply": "2023-11-21T01:26:30.415085Z",
     "shell.execute_reply.started": "2023-11-21T01:26:30.410893Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:26:33.941227Z",
     "iopub.status.busy": "2023-11-21T01:26:33.940555Z",
     "iopub.status.idle": "2023-11-21T01:26:33.945532Z",
     "shell.execute_reply": "2023-11-21T01:26:33.944739Z",
     "shell.execute_reply.started": "2023-11-21T01:26:33.941193Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_name = './L2_tune'\n",
    "os.makedirs(exp_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:59.371765Z",
     "iopub.status.busy": "2023-11-21T01:43:59.371372Z",
     "iopub.status.idle": "2023-11-21T01:43:59.391446Z",
     "shell.execute_reply": "2023-11-21T01:43:59.390657Z",
     "shell.execute_reply.started": "2023-11-21T01:43:59.371732Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "num_epochs = 100\n",
    "optim = \"adam\"\n",
    "mcp_save = ModelCheckpoint(f'{exp_name}/shufflenetv2_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "rlronp = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, min_lr=0.000001)\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optim,\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:44:03.271135Z",
     "iopub.status.busy": "2023-11-21T01:44:03.270215Z",
     "iopub.status.idle": "2023-11-21T02:53:38.174170Z",
     "shell.execute_reply": "2023-11-21T02:53:38.172596Z",
     "shell.execute_reply.started": "2023-11-21T01:44:03.271099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 00:07:26.948560: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-23 00:07:27.807094: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/625 [..............................] - ETA: 1:01 - loss: 6.4856 - sparse_categorical_accuracy: 0.0156  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0674s vs `on_train_batch_end` time: 0.1285s). Check your callbacks.\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 4.1518 - sparse_categorical_accuracy: 0.0963 - val_loss: 4.9361 - val_sparse_categorical_accuracy: 0.0203\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 140s 225ms/step - loss: 3.2579 - sparse_categorical_accuracy: 0.2274 - val_loss: 3.3272 - val_sparse_categorical_accuracy: 0.2160\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 2.7645 - sparse_categorical_accuracy: 0.3169 - val_loss: 2.9082 - val_sparse_categorical_accuracy: 0.2954\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 140s 225ms/step - loss: 2.3648 - sparse_categorical_accuracy: 0.3996 - val_loss: 2.6040 - val_sparse_categorical_accuracy: 0.3499\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 2.0331 - sparse_categorical_accuracy: 0.4719 - val_loss: 2.6708 - val_sparse_categorical_accuracy: 0.3544\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 1.7569 - sparse_categorical_accuracy: 0.5387 - val_loss: 2.3324 - val_sparse_categorical_accuracy: 0.4211\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 1.5269 - sparse_categorical_accuracy: 0.5969 - val_loss: 2.3523 - val_sparse_categorical_accuracy: 0.4334\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 140s 225ms/step - loss: 1.3101 - sparse_categorical_accuracy: 0.6492 - val_loss: 2.2605 - val_sparse_categorical_accuracy: 0.4537\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 1.1068 - sparse_categorical_accuracy: 0.7048 - val_loss: 2.2586 - val_sparse_categorical_accuracy: 0.4658\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 0.9238 - sparse_categorical_accuracy: 0.7568 - val_loss: 2.2538 - val_sparse_categorical_accuracy: 0.4882\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.7645 - sparse_categorical_accuracy: 0.8007 - val_loss: 2.6355 - val_sparse_categorical_accuracy: 0.4396\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6204 - sparse_categorical_accuracy: 0.8454"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    x=x_train,y=y_train,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val,y_val),\n",
    "    verbose=1,\n",
    "    callbacks=[mcp_save,rlronp],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['sparse_categorical_accuracy']\n",
    "val_acc=hist.history['val_sparse_categorical_accuracy']\n",
    "np.savez(os.path.join(exp_name, 'fit_history.npz'), train_loss=train_loss, val_loss=val_loss, train_acc=train_acc, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T03:01:35.270419Z",
     "iopub.status.busy": "2023-11-21T03:01:35.270058Z",
     "iopub.status.idle": "2023-11-21T03:01:35.277235Z",
     "shell.execute_reply": "2023-11-21T03:01:35.276344Z",
     "shell.execute_reply.started": "2023-11-21T03:01:35.270388Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss=model.history.history['loss']\n",
    "val_loss=model.history.history['val_loss']\n",
    "train_acc=model.history.history['sparse_categorical_accuracy']\n",
    "val_acc=model.history.history['val_sparse_categorical_accuracy']\n",
    "np.savez(os.path.join(exp_name, 'fit_history.npz'), train_loss=train_loss, val_loss=val_loss, train_acc=train_acc, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:53:58.007978Z",
     "iopub.status.busy": "2023-11-21T02:53:58.007409Z",
     "iopub.status.idle": "2023-11-21T02:55:11.103478Z",
     "shell.execute_reply": "2023-11-21T02:55:11.102729Z",
     "shell.execute_reply.started": "2023-11-21T02:53:58.007942Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 08:45:17.243567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-11-23 08:45:17.410935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:12:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-11-23 08:45:17.410974: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-23 08:45:17.555165: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-23 08:45:17.590605: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-23 08:45:17.613405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-23 08:45:17.730594: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-23 08:45:17.766014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-23 08:45:17.964402: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-23 08:45:17.967814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-23 08:45:17.968219: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-23 08:45:17.984397: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2700000000 Hz\n",
      "2023-11-23 08:45:17.985430: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x580a930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-23 08:45:17.985448: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-23 08:45:18.207175: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50c8180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-23 08:45:18.207206: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-11-23 08:45:18.211638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:12:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-11-23 08:45:18.211673: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-23 08:45:18.211694: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-23 08:45:18.211704: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-23 08:45:18.211712: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-23 08:45:18.211721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-23 08:45:18.211729: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-23 08:45:18.211738: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-23 08:45:18.217973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-23 08:45:18.221034: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-23 08:45:19.955762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-23 08:45:19.955797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-11-23 08:45:19.955803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-11-23 08:45:19.960300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13784 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:12:00.0, compute capability: 7.5)\n",
      "2023-11-23 08:45:24.083018: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-23 08:45:24.946119: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 33s 3ms/step - loss: 2.0647 - sparse_categorical_accuracy: 0.5686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0647149085998535, 0.5685999989509583]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_model = f'{exp_name}/shufflenetv2_model.hdf5'\n",
    "loaded_model_from_hdf5 = tf.keras.models.load_model(hdf5_model)\n",
    "loaded_model_from_hdf5.evaluate(x_test,y_test,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 C4M16G1",
   "language": "python",
   "name": "p3-c4m8-g1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
