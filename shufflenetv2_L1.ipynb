{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:23:46.827278Z",
     "iopub.status.busy": "2023-11-21T01:23:46.827022Z",
     "iopub.status.idle": "2023-11-21T01:24:04.286480Z",
     "shell.execute_reply": "2023-11-21T01:24:04.285623Z",
     "shell.execute_reply.started": "2023-11-21T01:23:46.827254Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:21:21.828329: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 22 13:21:30 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P4            Off  | 00000000:37:00.0 Off |                    0 |\r\n",
      "| N/A   27C    P8     6W /  75W |      0MiB /  7680MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import backend\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(fpath, label_key=\"labels\"):\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "\n",
    "    Args:\n",
    "        fpath: path the file to parse.\n",
    "        label_key: key for label data in the retrieve\n",
    "            dictionary.\n",
    "\n",
    "    Returns:\n",
    "        A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        d = cPickle.load(f, encoding=\"bytes\")\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode(\"utf8\")] = v\n",
    "        d = d_decoded\n",
    "    data = d[\"data\"]\n",
    "    labels = d[label_key]\n",
    "\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(label_mode=\"fine\"):\n",
    "    path = './cifar-100-python'\n",
    "\n",
    "    fpath = os.path.join(path, \"train\")\n",
    "    x_train, y_train = load_batch(fpath, label_key=label_mode + \"_labels\")\n",
    "\n",
    "    fpath = os.path.join(path, \"test\")\n",
    "    x_test, y_test = load_batch(fpath, label_key=label_mode + \"_labels\")\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "    if backend.image_data_format() == \"channels_last\":\n",
    "        x_train = x_train.transpose(0, 2, 3, 1)\n",
    "        x_test = x_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:24:50.355844Z",
     "iopub.status.busy": "2023-11-21T01:24:50.354792Z",
     "iopub.status.idle": "2023-11-21T01:24:56.079539Z",
     "shell.execute_reply": "2023-11-21T01:24:56.078730Z",
     "shell.execute_reply.started": "2023-11-21T01:24:50.355809Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train_val, y_train_val), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:24:59.032341Z",
     "iopub.status.busy": "2023-11-21T01:24:59.031600Z",
     "iopub.status.idle": "2023-11-21T01:24:59.039926Z",
     "shell.execute_reply": "2023-11-21T01:24:59.038736Z",
     "shell.execute_reply.started": "2023-11-21T01:24:59.032308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_val.shape, y_train_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:01.995440Z",
     "iopub.status.busy": "2023-11-21T01:25:01.995080Z",
     "iopub.status.idle": "2023-11-21T01:25:02.005737Z",
     "shell.execute_reply": "2023-11-21T01:25:02.004616Z",
     "shell.execute_reply.started": "2023-11-21T01:25:01.995409Z"
    }
   },
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "random_seed = 0\n",
    "num_train = x_train_val.shape[0]\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(val_size * num_train))\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "train_idx, val_idx = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:04.802527Z",
     "iopub.status.busy": "2023-11-21T01:25:04.802177Z",
     "iopub.status.idle": "2023-11-21T01:25:04.875391Z",
     "shell.execute_reply": "2023-11-21T01:25:04.874446Z",
     "shell.execute_reply.started": "2023-11-21T01:25:04.802498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val = x_train_val[train_idx], x_train_val[val_idx]\n",
    "y_train, y_val = y_train_val[train_idx], y_train_val[val_idx] \n",
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:27.690289Z",
     "iopub.status.busy": "2023-11-21T01:25:27.689762Z",
     "iopub.status.idle": "2023-11-21T01:25:27.704832Z",
     "shell.execute_reply": "2023-11-21T01:25:27.704071Z",
     "shell.execute_reply.started": "2023-11-21T01:25:27.690244Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import get_source_inputs\n",
    "from tensorflow.keras.layers import Activation, Add, Concatenate, Conv2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense\n",
    "from tensorflow.keras.layers import MaxPool2D, AveragePooling2D, BatchNormalization, Lambda, DepthwiseConv2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:30.628825Z",
     "iopub.status.busy": "2023-11-21T01:25:30.628461Z",
     "iopub.status.idle": "2023-11-21T01:25:30.649126Z",
     "shell.execute_reply": "2023-11-21T01:25:30.648158Z",
     "shell.execute_reply.started": "2023-11-21T01:25:30.628795Z"
    }
   },
   "outputs": [],
   "source": [
    "def channel_split(x, name=''):\n",
    "    # equipartition\n",
    "    in_channles = x.shape.as_list()[-1]\n",
    "    ip = in_channles // 2\n",
    "    c_hat = Lambda(lambda z: z[:, :, :, 0:ip], name='%s/sp%d_slice' % (name, 0))(x)\n",
    "    c = Lambda(lambda z: z[:, :, :, ip:], name='%s/sp%d_slice' % (name, 1))(x)\n",
    "    return c_hat, c\n",
    "\n",
    "def channel_shuffle(x):\n",
    "    height, width, channels = x.shape.as_list()[1:]\n",
    "    channels_per_split = channels // 2\n",
    "    x = K.reshape(x, (-1, height, width, 2, channels_per_split))\n",
    "    x = K.permute_dimensions(x, (0,1,2,4,3))\n",
    "    x = K.reshape(x, (-1, height, width, channels))\n",
    "    return x\n",
    "\n",
    "\n",
    "def shuffle_unit(inputs, out_channels, bottleneck_ratio,strides=2,stage=1,block=1):\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = -1\n",
    "    else:\n",
    "        raise ValueError('Only channels last supported')\n",
    "\n",
    "    prefix = 'stage{}/block{}'.format(stage, block)\n",
    "    bottleneck_channels = int(out_channels * bottleneck_ratio)\n",
    "    if strides < 2:\n",
    "        c_hat, c = channel_split(inputs, '{}/spl'.format(prefix))\n",
    "        inputs = c\n",
    "\n",
    "    x = Conv2D(bottleneck_channels, kernel_size=(1,1), strides=1, padding='same', name='{}/1x1conv_1'.format(prefix))(inputs)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_1'.format(prefix))(x)\n",
    "    x = Activation('relu', name='{}/relu_1x1conv_1'.format(prefix))(x)\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', name='{}/3x3dwconv'.format(prefix))(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv'.format(prefix))(x)\n",
    "    x = Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', name='{}/1x1conv_2'.format(prefix))(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_2'.format(prefix))(x)\n",
    "    x = Activation('relu', name='{}/relu_1x1conv_2'.format(prefix))(x)\n",
    "\n",
    "    if strides < 2:\n",
    "        ret = Concatenate(axis=bn_axis, name='{}/concat_1'.format(prefix))([x, c_hat])\n",
    "    else:\n",
    "        s2 = DepthwiseConv2D(kernel_size=3, strides=2, padding='same', name='{}/3x3dwconv_2'.format(prefix))(inputs)\n",
    "        s2 = BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv_2'.format(prefix))(s2)\n",
    "        s2 = Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', name='{}/1x1_conv_3'.format(prefix))(s2)\n",
    "        s2 = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_3'.format(prefix))(s2)\n",
    "        s2 = Activation('relu', name='{}/relu_1x1conv_3'.format(prefix))(s2)\n",
    "        ret = Concatenate(axis=bn_axis, name='{}/concat_2'.format(prefix))([x, s2])\n",
    "\n",
    "    ret = Lambda(channel_shuffle, name='{}/channel_shuffle'.format(prefix))(ret)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def block(x, channel_map, bottleneck_ratio, repeat=1, stage=1):\n",
    "    x = shuffle_unit(x, out_channels=channel_map[stage-1],\n",
    "                      strides=2,bottleneck_ratio=bottleneck_ratio,stage=stage,block=1)\n",
    "\n",
    "    for i in range(1, repeat+1):\n",
    "        x = shuffle_unit(x, out_channels=channel_map[stage-1],strides=1,\n",
    "                          bottleneck_ratio=bottleneck_ratio,stage=stage, block=(1+i))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:34.563376Z",
     "iopub.status.busy": "2023-11-21T01:25:34.562482Z",
     "iopub.status.idle": "2023-11-21T01:25:34.568704Z",
     "shell.execute_reply": "2023-11-21T01:25:34.567752Z",
     "shell.execute_reply.started": "2023-11-21T01:25:34.563334Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_augmentation_layer():\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.1),\n",
    "    ])\n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:37.062960Z",
     "iopub.status.busy": "2023-11-21T01:25:37.062086Z",
     "iopub.status.idle": "2023-11-21T01:25:37.067568Z",
     "shell.execute_reply": "2023-11-21T01:25:37.066743Z",
     "shell.execute_reply.started": "2023-11-21T01:25:37.062915Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_preprocess_layer():\n",
    "    data_preprocessing = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.Resizing(224, 224),\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    ])\n",
    "    return data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:39.199321Z",
     "iopub.status.busy": "2023-11-21T01:43:39.198317Z",
     "iopub.status.idle": "2023-11-21T01:43:39.215574Z",
     "shell.execute_reply": "2023-11-21T01:43:39.214765Z",
     "shell.execute_reply.started": "2023-11-21T01:43:39.199285Z"
    }
   },
   "outputs": [],
   "source": [
    "def ShuffleNetV2(include_top=True,\n",
    "                 input_tensor=None,\n",
    "                 scale_factor=1.0,\n",
    "                 pooling='max',\n",
    "                 input_shape=(224,224,3),\n",
    "                 load_model=None,\n",
    "                 num_shuffle_units=[3,7,3],\n",
    "                 bottleneck_ratio=1,\n",
    "                 classes=1000,\n",
    "                 augment=False,\n",
    "                 dropout=False,\n",
    "                 L1=False,\n",
    "                 L2=False):\n",
    "    if K.backend() != 'tensorflow':\n",
    "        raise RuntimeError('Only tensorflow supported for now')\n",
    "    name = 'ShuffleNetV2_{}_{}_{}'.format(scale_factor, bottleneck_ratio, \"\".join([str(x) for x in num_shuffle_units]))\n",
    "    out_dim_stage_two = {0.5:48, 1:116, 1.5:176, 2:244}\n",
    "\n",
    "    if pooling not in ['max', 'avg']:\n",
    "        raise ValueError('Invalid value for pooling')\n",
    "    if not (float(scale_factor)*4).is_integer():\n",
    "        raise ValueError('Invalid value for scale_factor, should be x over 4')\n",
    "    exp = np.insert(np.arange(len(num_shuffle_units), dtype=np.float32), 0, 0)  # [0., 0., 1., 2.]\n",
    "    out_channels_in_stage = 2**exp\n",
    "    out_channels_in_stage *= out_dim_stage_two[bottleneck_ratio]  #  calculate output channels for each stage\n",
    "    out_channels_in_stage[0] = 24  # first stage has always 24 output channels\n",
    "    out_channels_in_stage *= scale_factor\n",
    "    out_channels_in_stage = out_channels_in_stage.astype(int)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    \n",
    "    # data preprocessing\n",
    "    x = create_preprocess_layer()(img_input)\n",
    "    \n",
    "    # data augmentation\n",
    "    if augment:\n",
    "        x = create_augmentation_layer()(x)\n",
    "\n",
    "    # create shufflenet architecture\n",
    "    x = Conv2D(filters=out_channels_in_stage[0], kernel_size=(3, 3), padding='same', use_bias=False, strides=(2, 2),\n",
    "               activation='relu', name='conv1')(x)\n",
    "    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='maxpool1')(x)\n",
    "\n",
    "    # create stages containing shufflenet units beginning at stage 2\n",
    "    for stage in range(len(num_shuffle_units)):\n",
    "        repeat = num_shuffle_units[stage]\n",
    "        x = block(x, out_channels_in_stage,\n",
    "                   repeat=repeat,\n",
    "                   bottleneck_ratio=bottleneck_ratio,\n",
    "                   stage=stage + 2)\n",
    "\n",
    "    if bottleneck_ratio < 2:\n",
    "        k = 1024\n",
    "    else:\n",
    "        k = 2048\n",
    "    x = Conv2D(k, kernel_size=1, padding='same', strides=1, name='1x1conv5_out', activation='relu')(x)\n",
    "\n",
    "    if pooling == 'avg':\n",
    "        x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = GlobalMaxPooling2D(name='global_max_pool')(x)\n",
    "        \n",
    "    if dropout:\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    if include_top:\n",
    "        if L1:\n",
    "            x = Dense(classes, name='fc', kernel_regularizer=tf.keras.regularizers.l1(0.001))(x)\n",
    "        elif L2:\n",
    "            x = Dense(classes, name='fc', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "        else:\n",
    "            x = Dense(classes, name='fc')(x)\n",
    "        x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    if input_tensor:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    model = Model(inputs, x, name=name)\n",
    "\n",
    "    if load_model:\n",
    "        model.load_weights('', by_name=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:42.285699Z",
     "iopub.status.busy": "2023-11-21T01:43:42.285323Z",
     "iopub.status.idle": "2023-11-21T01:43:44.280038Z",
     "shell.execute_reply": "2023-11-21T01:43:44.278958Z",
     "shell.execute_reply.started": "2023-11-21T01:43:42.285656Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 08:43:29.450810: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-11-22 08:43:29.642934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:12:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-11-22 08:43:29.642977: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 08:43:29.792712: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 08:43:29.835510: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-22 08:43:29.854852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-22 08:43:29.968612: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-22 08:43:30.005152: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-22 08:43:30.212052: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-22 08:43:30.216925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-22 08:43:30.217644: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 08:43:30.231082: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2700000000 Hz\n",
      "2023-11-22 08:43:30.232620: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8334390 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 08:43:30.232639: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-22 08:43:30.418284: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x834fee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 08:43:30.418317: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-11-22 08:43:30.422001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:12:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-11-22 08:43:30.422035: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 08:43:30.422058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 08:43:30.422067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-22 08:43:30.422076: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-22 08:43:30.422085: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-22 08:43:30.422094: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-22 08:43:30.422103: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-22 08:43:30.424727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-22 08:43:30.427877: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 08:43:32.416246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-22 08:43:32.416287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-11-22 08:43:32.416294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-11-22 08:43:32.422463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13784 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:12:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ShuffleNetV2_1.0_1_373\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 24) 648         sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 56, 56, 24)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1conv_1 (Conv2D (None, 56, 56, 116)  2900        maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_1 (Bat (None, 56, 56, 116)  464         stage2/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_1 (A (None, 56, 56, 116)  0           stage2/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/3x3dwconv_2 (Dept (None, 28, 28, 24)   240         maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_3x3dwconv_2 (B (None, 28, 28, 24)   96          stage2/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1_conv_3 (Conv2 (None, 28, 28, 116)  2900        stage2/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_3 (Bat (None, 28, 28, 116)  464         stage2/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_3 (A (None, 28, 28, 116)  0           stage2/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/concat_2 (Concate (None, 28, 28, 232)  0           stage2/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1conv_1 (Conv2D (None, 28, 28, 232)  54056       stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_1 (Bat (None, 28, 28, 232)  928         stage3/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_1 (A (None, 28, 28, 232)  0           stage3/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/3x3dwconv_2 (Dept (None, 14, 14, 232)  2320        stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_3x3dwconv_2 (B (None, 14, 14, 232)  928         stage3/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1_conv_3 (Conv2 (None, 14, 14, 232)  54056       stage3/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_3 (Bat (None, 14, 14, 232)  928         stage3/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_3 (A (None, 14, 14, 232)  0           stage3/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/concat_2 (Concate (None, 14, 14, 464)  0           stage3/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block5/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block5/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block5/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block5/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block5/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block5/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block5/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block5/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block5/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block5/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block5/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block6/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block6/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block6/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block6/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block6/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block6/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block6/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block6/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block6/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block6/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block6/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block7/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block7/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block7/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block7/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block7/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block7/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block7/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block7/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block7/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block7/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block7/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block8/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block8/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block8/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block8/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block8/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block8/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block8/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block8/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block8/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block8/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block8/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1conv_1 (Conv2D (None, 14, 14, 464)  215760      stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_1 (Bat (None, 14, 14, 464)  1856        stage4/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_1 (A (None, 14, 14, 464)  0           stage4/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/3x3dwconv_2 (Dept (None, 7, 7, 464)    4640        stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_3x3dwconv_2 (B (None, 7, 7, 464)    1856        stage4/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_conv_3 (Conv2 (None, 7, 7, 464)    215760      stage4/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_3 (Bat (None, 7, 7, 464)    1856        stage4/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_3 (A (None, 7, 7, 464)    0           stage4/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/concat_2 (Concate (None, 7, 7, 928)    0           stage4/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "1x1conv5_out (Conv2D)           (None, 7, 7, 1024)   951296      stage4/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (GlobalMaxPooli (None, 1024)         0           1x1conv5_out[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 100)          102500      global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 100)          0           fc[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 4,121,240\n",
      "Trainable params: 4,093,120\n",
      "Non-trainable params: 28,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ShuffleNetV2(include_top=True, input_shape=(32, 32, 3), bottleneck_ratio=1, classes=100, L1=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:26:30.410929Z",
     "iopub.status.busy": "2023-11-21T01:26:30.410201Z",
     "iopub.status.idle": "2023-11-21T01:26:30.415945Z",
     "shell.execute_reply": "2023-11-21T01:26:30.415085Z",
     "shell.execute_reply.started": "2023-11-21T01:26:30.410893Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:26:33.941227Z",
     "iopub.status.busy": "2023-11-21T01:26:33.940555Z",
     "iopub.status.idle": "2023-11-21T01:26:33.945532Z",
     "shell.execute_reply": "2023-11-21T01:26:33.944739Z",
     "shell.execute_reply.started": "2023-11-21T01:26:33.941193Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_name = './L1'\n",
    "os.makedirs(exp_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:59.371765Z",
     "iopub.status.busy": "2023-11-21T01:43:59.371372Z",
     "iopub.status.idle": "2023-11-21T01:43:59.391446Z",
     "shell.execute_reply": "2023-11-21T01:43:59.390657Z",
     "shell.execute_reply.started": "2023-11-21T01:43:59.371732Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "num_epochs = 100\n",
    "optim = \"adam\"\n",
    "mcp_save = ModelCheckpoint(f'{exp_name}/shufflenetv2_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "rlronp = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, min_lr=0.000001)\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optim,\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:44:03.271135Z",
     "iopub.status.busy": "2023-11-21T01:44:03.270215Z",
     "iopub.status.idle": "2023-11-21T02:53:38.174170Z",
     "shell.execute_reply": "2023-11-21T02:53:38.172596Z",
     "shell.execute_reply.started": "2023-11-21T01:44:03.271099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 08:43:53.039577: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 08:43:54.031173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/625 [..............................] - ETA: 1:01 - loss: 10.1136 - sparse_categorical_accuracy: 0.0078  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0673s vs `on_train_batch_end` time: 0.1282s). Check your callbacks.\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 5.3477 - sparse_categorical_accuracy: 0.0980 - val_loss: 4.9336 - val_sparse_categorical_accuracy: 0.0329\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 140s 225ms/step - loss: 3.4893 - sparse_categorical_accuracy: 0.2209 - val_loss: 3.5797 - val_sparse_categorical_accuracy: 0.2160\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 3.0292 - sparse_categorical_accuracy: 0.3069 - val_loss: 3.0697 - val_sparse_categorical_accuracy: 0.3009\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 2.6421 - sparse_categorical_accuracy: 0.3861 - val_loss: 3.0987 - val_sparse_categorical_accuracy: 0.3237\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 140s 225ms/step - loss: 2.3327 - sparse_categorical_accuracy: 0.4549 - val_loss: 2.5255 - val_sparse_categorical_accuracy: 0.4107\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 2.0796 - sparse_categorical_accuracy: 0.5107 - val_loss: 2.5176 - val_sparse_categorical_accuracy: 0.4256\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 1.8674 - sparse_categorical_accuracy: 0.5623 - val_loss: 2.4568 - val_sparse_categorical_accuracy: 0.4422\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 1.6741 - sparse_categorical_accuracy: 0.6097 - val_loss: 2.3792 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 1.4905 - sparse_categorical_accuracy: 0.6556 - val_loss: 2.3935 - val_sparse_categorical_accuracy: 0.4772\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 140s 225ms/step - loss: 1.3056 - sparse_categorical_accuracy: 0.7057 - val_loss: 2.2544 - val_sparse_categorical_accuracy: 0.5017\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 1.1480 - sparse_categorical_accuracy: 0.7474 - val_loss: 2.3282 - val_sparse_categorical_accuracy: 0.5012\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.9685 - sparse_categorical_accuracy: 0.7975\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.9685 - sparse_categorical_accuracy: 0.7975 - val_loss: 2.4411 - val_sparse_categorical_accuracy: 0.4857\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 0.5318 - sparse_categorical_accuracy: 0.9270 - val_loss: 2.1571 - val_sparse_categorical_accuracy: 0.5507\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.3099 - sparse_categorical_accuracy: 0.9860 - val_loss: 2.1991 - val_sparse_categorical_accuracy: 0.5553\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2385 - sparse_categorical_accuracy: 0.9967\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.2385 - sparse_categorical_accuracy: 0.9967 - val_loss: 2.2436 - val_sparse_categorical_accuracy: 0.5491\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1913 - sparse_categorical_accuracy: 0.9993 - val_loss: 2.1733 - val_sparse_categorical_accuracy: 0.5604\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1676 - sparse_categorical_accuracy: 0.9996\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1676 - sparse_categorical_accuracy: 0.9996 - val_loss: 2.1919 - val_sparse_categorical_accuracy: 0.5554\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1501 - sparse_categorical_accuracy: 0.9997 - val_loss: 2.1921 - val_sparse_categorical_accuracy: 0.5517\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1399 - sparse_categorical_accuracy: 0.9997\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1399 - sparse_categorical_accuracy: 0.9997 - val_loss: 2.2103 - val_sparse_categorical_accuracy: 0.5502\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1302 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2096 - val_sparse_categorical_accuracy: 0.5481\n",
      "Epoch 21/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1245 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1245 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2269 - val_sparse_categorical_accuracy: 0.5449\n",
      "Epoch 22/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1184 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2302 - val_sparse_categorical_accuracy: 0.5434\n",
      "Epoch 23/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1148 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1148 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2397 - val_sparse_categorical_accuracy: 0.5415\n",
      "Epoch 24/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2474 - val_sparse_categorical_accuracy: 0.5396\n",
      "Epoch 25/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1089 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2516 - val_sparse_categorical_accuracy: 0.5394\n",
      "Epoch 26/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1070 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2560 - val_sparse_categorical_accuracy: 0.5366\n",
      "Epoch 27/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1059 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1059 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2596 - val_sparse_categorical_accuracy: 0.5387\n",
      "Epoch 28/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1048 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2610 - val_sparse_categorical_accuracy: 0.5375\n",
      "Epoch 29/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1041 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2652 - val_sparse_categorical_accuracy: 0.5369\n",
      "Epoch 30/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1037 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2661 - val_sparse_categorical_accuracy: 0.5372\n",
      "Epoch 31/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1033 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1033 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2674 - val_sparse_categorical_accuracy: 0.5371\n",
      "Epoch 32/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1029 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2670 - val_sparse_categorical_accuracy: 0.5367\n",
      "Epoch 33/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1028 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2685 - val_sparse_categorical_accuracy: 0.5356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1026 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2696 - val_sparse_categorical_accuracy: 0.5369\n",
      "Epoch 35/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1025 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2697 - val_sparse_categorical_accuracy: 0.5367\n",
      "Epoch 36/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1022 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2710 - val_sparse_categorical_accuracy: 0.5361\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1022 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2715 - val_sparse_categorical_accuracy: 0.5351\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1019 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2721 - val_sparse_categorical_accuracy: 0.5352\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1019 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2744 - val_sparse_categorical_accuracy: 0.5361\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1017 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2751 - val_sparse_categorical_accuracy: 0.5352\n",
      "Epoch 41/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1014 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2747 - val_sparse_categorical_accuracy: 0.5356\n",
      "Epoch 42/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1015 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2748 - val_sparse_categorical_accuracy: 0.5351\n",
      "Epoch 43/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1012 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2774 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 44/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1010 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2767 - val_sparse_categorical_accuracy: 0.5354\n",
      "Epoch 45/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1009 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2771 - val_sparse_categorical_accuracy: 0.5352\n",
      "Epoch 46/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1008 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2777 - val_sparse_categorical_accuracy: 0.5353\n",
      "Epoch 47/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1006 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2786 - val_sparse_categorical_accuracy: 0.5346\n",
      "Epoch 48/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1004 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2798 - val_sparse_categorical_accuracy: 0.5345\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1002 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2795 - val_sparse_categorical_accuracy: 0.5352\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.1001 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2793 - val_sparse_categorical_accuracy: 0.5345\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0999 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2818 - val_sparse_categorical_accuracy: 0.5349\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2823 - val_sparse_categorical_accuracy: 0.5344\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0997 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2823 - val_sparse_categorical_accuracy: 0.5343\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0995 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2826 - val_sparse_categorical_accuracy: 0.5345\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0994 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2842 - val_sparse_categorical_accuracy: 0.5342\n",
      "Epoch 56/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2839 - val_sparse_categorical_accuracy: 0.5341\n",
      "Epoch 57/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0990 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2853 - val_sparse_categorical_accuracy: 0.5342\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0990 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2854 - val_sparse_categorical_accuracy: 0.5344\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0987 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2862 - val_sparse_categorical_accuracy: 0.5330\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0986 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2870 - val_sparse_categorical_accuracy: 0.5341\n",
      "Epoch 61/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0984 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2871 - val_sparse_categorical_accuracy: 0.5341\n",
      "Epoch 62/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2885 - val_sparse_categorical_accuracy: 0.5341\n",
      "Epoch 63/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2882 - val_sparse_categorical_accuracy: 0.5337\n",
      "Epoch 64/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0980 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2893 - val_sparse_categorical_accuracy: 0.5332\n",
      "Epoch 65/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0977 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2916 - val_sparse_categorical_accuracy: 0.5340\n",
      "Epoch 66/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0977 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2901 - val_sparse_categorical_accuracy: 0.5331\n",
      "Epoch 67/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0977 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2915 - val_sparse_categorical_accuracy: 0.5327\n",
      "Epoch 68/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2923 - val_sparse_categorical_accuracy: 0.5332\n",
      "Epoch 69/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2930 - val_sparse_categorical_accuracy: 0.5325\n",
      "Epoch 70/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0972 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2927 - val_sparse_categorical_accuracy: 0.5328\n",
      "Epoch 71/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2949 - val_sparse_categorical_accuracy: 0.5323\n",
      "Epoch 72/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0969 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2943 - val_sparse_categorical_accuracy: 0.5319\n",
      "Epoch 73/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2952 - val_sparse_categorical_accuracy: 0.5318\n",
      "Epoch 74/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0966 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2961 - val_sparse_categorical_accuracy: 0.5320\n",
      "Epoch 75/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0965 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2973 - val_sparse_categorical_accuracy: 0.5314\n",
      "Epoch 76/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0963 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2961 - val_sparse_categorical_accuracy: 0.5317\n",
      "Epoch 77/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0960 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2973 - val_sparse_categorical_accuracy: 0.5316\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0960 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.2982 - val_sparse_categorical_accuracy: 0.5317\n",
      "Epoch 79/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0959 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2985 - val_sparse_categorical_accuracy: 0.5316\n",
      "Epoch 80/100\n",
      "625/625 [==============================] - 140s 225ms/step - loss: 0.0957 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.3002 - val_sparse_categorical_accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0955 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.2993 - val_sparse_categorical_accuracy: 0.5316\n",
      "Epoch 82/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0954 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.3005 - val_sparse_categorical_accuracy: 0.5317\n",
      "Epoch 83/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.3020 - val_sparse_categorical_accuracy: 0.5323\n",
      "Epoch 84/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0951 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.3018 - val_sparse_categorical_accuracy: 0.5316\n",
      "Epoch 85/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0951 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.3024 - val_sparse_categorical_accuracy: 0.5317\n",
      "Epoch 86/100\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.0949 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.3027 - val_sparse_categorical_accuracy: 0.5314\n",
      "Epoch 87/100\n",
      "113/625 [====>.........................] - ETA: 1:46 - loss: 0.0947 - sparse_categorical_accuracy: 0.9999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    x=x_train,y=y_train,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val,y_val),\n",
    "    verbose=1,\n",
    "    callbacks=[mcp_save,rlronp],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['sparse_categorical_accuracy']\n",
    "val_acc=hist.history['val_sparse_categorical_accuracy']\n",
    "np.savez(os.path.join(exp_name, 'fit_history.npz'), train_loss=train_loss, val_loss=val_loss, train_acc=train_acc, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T03:01:35.270419Z",
     "iopub.status.busy": "2023-11-21T03:01:35.270058Z",
     "iopub.status.idle": "2023-11-21T03:01:35.277235Z",
     "shell.execute_reply": "2023-11-21T03:01:35.276344Z",
     "shell.execute_reply.started": "2023-11-21T03:01:35.270388Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss=model.history.history['loss']\n",
    "val_loss=model.history.history['val_loss']\n",
    "train_acc=model.history.history['sparse_categorical_accuracy']\n",
    "val_acc=model.history.history['val_sparse_categorical_accuracy']\n",
    "np.savez(os.path.join(exp_name, 'fit_history.npz'), train_loss=train_loss, val_loss=val_loss, train_acc=train_acc, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:53:58.007978Z",
     "iopub.status.busy": "2023-11-21T02:53:58.007409Z",
     "iopub.status.idle": "2023-11-21T02:55:11.103478Z",
     "shell.execute_reply": "2023-11-21T02:55:11.102729Z",
     "shell.execute_reply.started": "2023-11-21T02:53:58.007942Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:22:02.998669: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-11-22 13:22:03.018381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:37:00.0 name: Tesla P4 computeCapability: 6.1\n",
      "coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2023-11-22 13:22:03.018422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 13:22:03.151450: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 13:22:03.183799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-22 13:22:03.202911: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-22 13:22:03.311342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-22 13:22:03.346444: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-22 13:22:03.529882: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-22 13:22:03.530737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-22 13:22:03.531277: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 13:22:03.552252: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600000000 Hz\n",
      "2023-11-22 13:22:03.553823: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x68cce00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 13:22:03.553841: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-22 13:22:03.644552: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x618a670 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 13:22:03.644601: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
      "2023-11-22 13:22:03.648144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:37:00.0 name: Tesla P4 computeCapability: 6.1\n",
      "coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2023-11-22 13:22:03.648178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 13:22:03.648201: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 13:22:03.648213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-22 13:22:03.648224: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-22 13:22:03.648235: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-22 13:22:03.648245: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-22 13:22:03.648257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-22 13:22:03.648700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-22 13:22:03.651905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 13:22:05.413599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-22 13:22:05.413635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-11-22 13:22:05.413643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-11-22 13:22:05.415270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6951 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:37:00.0, compute capability: 6.1)\n",
      "2023-11-22 13:22:09.505557: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 13:22:10.382116: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 52s 5ms/step - loss: 2.1171 - sparse_categorical_accuracy: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.117079734802246, 0.5555999875068665]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_model = f'{exp_name}/shufflenetv2_model.hdf5'\n",
    "loaded_model_from_hdf5 = tf.keras.models.load_model(hdf5_model)\n",
    "loaded_model_from_hdf5.evaluate(x_test,y_test,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 C4M16G1",
   "language": "python",
   "name": "p3-c4m8-g1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
