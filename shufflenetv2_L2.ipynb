{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:23:46.827278Z",
     "iopub.status.busy": "2023-11-21T01:23:46.827022Z",
     "iopub.status.idle": "2023-11-21T01:24:04.286480Z",
     "shell.execute_reply": "2023-11-21T01:24:04.285623Z",
     "shell.execute_reply.started": "2023-11-21T01:23:46.827254Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:29:05.809616: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 22 19:29:26 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P4            Off  | 00000000:37:00.0 Off |                    0 |\r\n",
      "| N/A   27C    P8     6W /  75W |      0MiB /  7680MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import backend\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(fpath, label_key=\"labels\"):\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "\n",
    "    Args:\n",
    "        fpath: path the file to parse.\n",
    "        label_key: key for label data in the retrieve\n",
    "            dictionary.\n",
    "\n",
    "    Returns:\n",
    "        A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        d = cPickle.load(f, encoding=\"bytes\")\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode(\"utf8\")] = v\n",
    "        d = d_decoded\n",
    "    data = d[\"data\"]\n",
    "    labels = d[label_key]\n",
    "\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(label_mode=\"fine\"):\n",
    "    path = './cifar-100-python'\n",
    "\n",
    "    fpath = os.path.join(path, \"train\")\n",
    "    x_train, y_train = load_batch(fpath, label_key=label_mode + \"_labels\")\n",
    "\n",
    "    fpath = os.path.join(path, \"test\")\n",
    "    x_test, y_test = load_batch(fpath, label_key=label_mode + \"_labels\")\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "    if backend.image_data_format() == \"channels_last\":\n",
    "        x_train = x_train.transpose(0, 2, 3, 1)\n",
    "        x_test = x_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:24:50.355844Z",
     "iopub.status.busy": "2023-11-21T01:24:50.354792Z",
     "iopub.status.idle": "2023-11-21T01:24:56.079539Z",
     "shell.execute_reply": "2023-11-21T01:24:56.078730Z",
     "shell.execute_reply.started": "2023-11-21T01:24:50.355809Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train_val, y_train_val), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:24:59.032341Z",
     "iopub.status.busy": "2023-11-21T01:24:59.031600Z",
     "iopub.status.idle": "2023-11-21T01:24:59.039926Z",
     "shell.execute_reply": "2023-11-21T01:24:59.038736Z",
     "shell.execute_reply.started": "2023-11-21T01:24:59.032308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_val.shape, y_train_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:01.995440Z",
     "iopub.status.busy": "2023-11-21T01:25:01.995080Z",
     "iopub.status.idle": "2023-11-21T01:25:02.005737Z",
     "shell.execute_reply": "2023-11-21T01:25:02.004616Z",
     "shell.execute_reply.started": "2023-11-21T01:25:01.995409Z"
    }
   },
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "random_seed = 0\n",
    "num_train = x_train_val.shape[0]\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(val_size * num_train))\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "train_idx, val_idx = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:04.802527Z",
     "iopub.status.busy": "2023-11-21T01:25:04.802177Z",
     "iopub.status.idle": "2023-11-21T01:25:04.875391Z",
     "shell.execute_reply": "2023-11-21T01:25:04.874446Z",
     "shell.execute_reply.started": "2023-11-21T01:25:04.802498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val = x_train_val[train_idx], x_train_val[val_idx]\n",
    "y_train, y_val = y_train_val[train_idx], y_train_val[val_idx] \n",
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:27.690289Z",
     "iopub.status.busy": "2023-11-21T01:25:27.689762Z",
     "iopub.status.idle": "2023-11-21T01:25:27.704832Z",
     "shell.execute_reply": "2023-11-21T01:25:27.704071Z",
     "shell.execute_reply.started": "2023-11-21T01:25:27.690244Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import get_source_inputs\n",
    "from tensorflow.keras.layers import Activation, Add, Concatenate, Conv2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense\n",
    "from tensorflow.keras.layers import MaxPool2D, AveragePooling2D, BatchNormalization, Lambda, DepthwiseConv2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:30.628825Z",
     "iopub.status.busy": "2023-11-21T01:25:30.628461Z",
     "iopub.status.idle": "2023-11-21T01:25:30.649126Z",
     "shell.execute_reply": "2023-11-21T01:25:30.648158Z",
     "shell.execute_reply.started": "2023-11-21T01:25:30.628795Z"
    }
   },
   "outputs": [],
   "source": [
    "def channel_split(x, name=''):\n",
    "    # equipartition\n",
    "    in_channles = x.shape.as_list()[-1]\n",
    "    ip = in_channles // 2\n",
    "    c_hat = Lambda(lambda z: z[:, :, :, 0:ip], name='%s/sp%d_slice' % (name, 0))(x)\n",
    "    c = Lambda(lambda z: z[:, :, :, ip:], name='%s/sp%d_slice' % (name, 1))(x)\n",
    "    return c_hat, c\n",
    "\n",
    "def channel_shuffle(x):\n",
    "    height, width, channels = x.shape.as_list()[1:]\n",
    "    channels_per_split = channels // 2\n",
    "    x = K.reshape(x, (-1, height, width, 2, channels_per_split))\n",
    "    x = K.permute_dimensions(x, (0,1,2,4,3))\n",
    "    x = K.reshape(x, (-1, height, width, channels))\n",
    "    return x\n",
    "\n",
    "\n",
    "def shuffle_unit(inputs, out_channels, bottleneck_ratio,strides=2,stage=1,block=1):\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = -1\n",
    "    else:\n",
    "        raise ValueError('Only channels last supported')\n",
    "\n",
    "    prefix = 'stage{}/block{}'.format(stage, block)\n",
    "    bottleneck_channels = int(out_channels * bottleneck_ratio)\n",
    "    if strides < 2:\n",
    "        c_hat, c = channel_split(inputs, '{}/spl'.format(prefix))\n",
    "        inputs = c\n",
    "\n",
    "    x = Conv2D(bottleneck_channels, kernel_size=(1,1), strides=1, padding='same', name='{}/1x1conv_1'.format(prefix))(inputs)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_1'.format(prefix))(x)\n",
    "    x = Activation('relu', name='{}/relu_1x1conv_1'.format(prefix))(x)\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', name='{}/3x3dwconv'.format(prefix))(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv'.format(prefix))(x)\n",
    "    x = Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', name='{}/1x1conv_2'.format(prefix))(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_2'.format(prefix))(x)\n",
    "    x = Activation('relu', name='{}/relu_1x1conv_2'.format(prefix))(x)\n",
    "\n",
    "    if strides < 2:\n",
    "        ret = Concatenate(axis=bn_axis, name='{}/concat_1'.format(prefix))([x, c_hat])\n",
    "    else:\n",
    "        s2 = DepthwiseConv2D(kernel_size=3, strides=2, padding='same', name='{}/3x3dwconv_2'.format(prefix))(inputs)\n",
    "        s2 = BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv_2'.format(prefix))(s2)\n",
    "        s2 = Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', name='{}/1x1_conv_3'.format(prefix))(s2)\n",
    "        s2 = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_3'.format(prefix))(s2)\n",
    "        s2 = Activation('relu', name='{}/relu_1x1conv_3'.format(prefix))(s2)\n",
    "        ret = Concatenate(axis=bn_axis, name='{}/concat_2'.format(prefix))([x, s2])\n",
    "\n",
    "    ret = Lambda(channel_shuffle, name='{}/channel_shuffle'.format(prefix))(ret)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def block(x, channel_map, bottleneck_ratio, repeat=1, stage=1):\n",
    "    x = shuffle_unit(x, out_channels=channel_map[stage-1],\n",
    "                      strides=2,bottleneck_ratio=bottleneck_ratio,stage=stage,block=1)\n",
    "\n",
    "    for i in range(1, repeat+1):\n",
    "        x = shuffle_unit(x, out_channels=channel_map[stage-1],strides=1,\n",
    "                          bottleneck_ratio=bottleneck_ratio,stage=stage, block=(1+i))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:34.563376Z",
     "iopub.status.busy": "2023-11-21T01:25:34.562482Z",
     "iopub.status.idle": "2023-11-21T01:25:34.568704Z",
     "shell.execute_reply": "2023-11-21T01:25:34.567752Z",
     "shell.execute_reply.started": "2023-11-21T01:25:34.563334Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_augmentation_layer():\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.1),\n",
    "    ])\n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:25:37.062960Z",
     "iopub.status.busy": "2023-11-21T01:25:37.062086Z",
     "iopub.status.idle": "2023-11-21T01:25:37.067568Z",
     "shell.execute_reply": "2023-11-21T01:25:37.066743Z",
     "shell.execute_reply.started": "2023-11-21T01:25:37.062915Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_preprocess_layer():\n",
    "    data_preprocessing = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.Resizing(224, 224),\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    ])\n",
    "    return data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:39.199321Z",
     "iopub.status.busy": "2023-11-21T01:43:39.198317Z",
     "iopub.status.idle": "2023-11-21T01:43:39.215574Z",
     "shell.execute_reply": "2023-11-21T01:43:39.214765Z",
     "shell.execute_reply.started": "2023-11-21T01:43:39.199285Z"
    }
   },
   "outputs": [],
   "source": [
    "def ShuffleNetV2(include_top=True,\n",
    "                 input_tensor=None,\n",
    "                 scale_factor=1.0,\n",
    "                 pooling='max',\n",
    "                 input_shape=(224,224,3),\n",
    "                 load_model=None,\n",
    "                 num_shuffle_units=[3,7,3],\n",
    "                 bottleneck_ratio=1,\n",
    "                 classes=1000,\n",
    "                 augment=False,\n",
    "                 dropout=False,\n",
    "                 L1=False,\n",
    "                 L2=False):\n",
    "    if K.backend() != 'tensorflow':\n",
    "        raise RuntimeError('Only tensorflow supported for now')\n",
    "    name = 'ShuffleNetV2_{}_{}_{}'.format(scale_factor, bottleneck_ratio, \"\".join([str(x) for x in num_shuffle_units]))\n",
    "    out_dim_stage_two = {0.5:48, 1:116, 1.5:176, 2:244}\n",
    "\n",
    "    if pooling not in ['max', 'avg']:\n",
    "        raise ValueError('Invalid value for pooling')\n",
    "    if not (float(scale_factor)*4).is_integer():\n",
    "        raise ValueError('Invalid value for scale_factor, should be x over 4')\n",
    "    exp = np.insert(np.arange(len(num_shuffle_units), dtype=np.float32), 0, 0)  # [0., 0., 1., 2.]\n",
    "    out_channels_in_stage = 2**exp\n",
    "    out_channels_in_stage *= out_dim_stage_two[bottleneck_ratio]  #  calculate output channels for each stage\n",
    "    out_channels_in_stage[0] = 24  # first stage has always 24 output channels\n",
    "    out_channels_in_stage *= scale_factor\n",
    "    out_channels_in_stage = out_channels_in_stage.astype(int)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    \n",
    "    # data preprocessing\n",
    "    x = create_preprocess_layer()(img_input)\n",
    "    \n",
    "    # data augmentation\n",
    "    if augment:\n",
    "        x = create_augmentation_layer()(x)\n",
    "\n",
    "    # create shufflenet architecture\n",
    "    x = Conv2D(filters=out_channels_in_stage[0], kernel_size=(3, 3), padding='same', use_bias=False, strides=(2, 2),\n",
    "               activation='relu', name='conv1')(x)\n",
    "    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='maxpool1')(x)\n",
    "\n",
    "    # create stages containing shufflenet units beginning at stage 2\n",
    "    for stage in range(len(num_shuffle_units)):\n",
    "        repeat = num_shuffle_units[stage]\n",
    "        x = block(x, out_channels_in_stage,\n",
    "                   repeat=repeat,\n",
    "                   bottleneck_ratio=bottleneck_ratio,\n",
    "                   stage=stage + 2)\n",
    "\n",
    "    if bottleneck_ratio < 2:\n",
    "        k = 1024\n",
    "    else:\n",
    "        k = 2048\n",
    "    x = Conv2D(k, kernel_size=1, padding='same', strides=1, name='1x1conv5_out', activation='relu')(x)\n",
    "\n",
    "    if pooling == 'avg':\n",
    "        x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = GlobalMaxPooling2D(name='global_max_pool')(x)\n",
    "        \n",
    "    if dropout:\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    if include_top:\n",
    "        if L1:\n",
    "            x = Dense(classes, name='fc', kernel_regularizer=tf.keras.regularizers.l1(0.001))(x)\n",
    "        elif L2:\n",
    "            x = Dense(classes, name='fc', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "        else:\n",
    "            x = Dense(classes, name='fc')(x)\n",
    "        x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    if input_tensor:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    model = Model(inputs, x, name=name)\n",
    "\n",
    "    if load_model:\n",
    "        model.load_weights('', by_name=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:42.285699Z",
     "iopub.status.busy": "2023-11-21T01:43:42.285323Z",
     "iopub.status.idle": "2023-11-21T01:43:44.280038Z",
     "shell.execute_reply": "2023-11-21T01:43:44.278958Z",
     "shell.execute_reply.started": "2023-11-21T01:43:42.285656Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:33:55.609537: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-11-22 13:33:55.774368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:12:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-11-22 13:33:55.774402: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 13:33:55.797841: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 13:33:55.810274: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-22 13:33:55.814427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-22 13:33:55.838664: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-22 13:33:55.844095: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-22 13:33:55.892509: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-22 13:33:55.895735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-22 13:33:55.896192: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 13:33:55.906127: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2700000000 Hz\n",
      "2023-11-22 13:33:55.907622: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x88ab310 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 13:33:55.907638: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-22 13:33:56.097726: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x88c6e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 13:33:56.097755: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-11-22 13:33:56.100117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:12:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-11-22 13:33:56.100150: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 13:33:56.100172: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 13:33:56.100181: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-22 13:33:56.100190: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-22 13:33:56.100198: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-22 13:33:56.100207: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-22 13:33:56.100216: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-22 13:33:56.102976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-22 13:33:56.103624: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 13:33:56.840536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-22 13:33:56.840567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-11-22 13:33:56.840574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-11-22 13:33:56.845111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13784 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:12:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ShuffleNetV2_1.0_1_373\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 24) 648         sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 56, 56, 24)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1conv_1 (Conv2D (None, 56, 56, 116)  2900        maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_1 (Bat (None, 56, 56, 116)  464         stage2/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_1 (A (None, 56, 56, 116)  0           stage2/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/3x3dwconv_2 (Dept (None, 28, 28, 24)   240         maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_3x3dwconv_2 (B (None, 28, 28, 24)   96          stage2/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1_conv_3 (Conv2 (None, 28, 28, 116)  2900        stage2/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_3 (Bat (None, 28, 28, 116)  464         stage2/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_3 (A (None, 28, 28, 116)  0           stage2/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/concat_2 (Concate (None, 28, 28, 232)  0           stage2/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1conv_1 (Conv2D (None, 28, 28, 232)  54056       stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_1 (Bat (None, 28, 28, 232)  928         stage3/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_1 (A (None, 28, 28, 232)  0           stage3/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/3x3dwconv_2 (Dept (None, 14, 14, 232)  2320        stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_3x3dwconv_2 (B (None, 14, 14, 232)  928         stage3/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1_conv_3 (Conv2 (None, 14, 14, 232)  54056       stage3/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_3 (Bat (None, 14, 14, 232)  928         stage3/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_3 (A (None, 14, 14, 232)  0           stage3/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/concat_2 (Concate (None, 14, 14, 464)  0           stage3/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block5/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block5/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block5/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block5/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block5/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block5/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block5/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block5/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block5/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block5/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block5/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block6/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block6/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block6/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block6/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block6/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block6/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block6/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block6/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block6/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block6/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block6/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block7/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block7/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block7/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block7/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block7/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block7/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block7/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block7/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block7/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block7/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block7/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block8/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block8/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block8/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block8/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block8/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block8/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block8/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block8/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block8/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block8/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block8/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1conv_1 (Conv2D (None, 14, 14, 464)  215760      stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_1 (Bat (None, 14, 14, 464)  1856        stage4/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_1 (A (None, 14, 14, 464)  0           stage4/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/3x3dwconv_2 (Dept (None, 7, 7, 464)    4640        stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_3x3dwconv_2 (B (None, 7, 7, 464)    1856        stage4/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_conv_3 (Conv2 (None, 7, 7, 464)    215760      stage4/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_3 (Bat (None, 7, 7, 464)    1856        stage4/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_3 (A (None, 7, 7, 464)    0           stage4/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/concat_2 (Concate (None, 7, 7, 928)    0           stage4/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "1x1conv5_out (Conv2D)           (None, 7, 7, 1024)   951296      stage4/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (GlobalMaxPooli (None, 1024)         0           1x1conv5_out[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 100)          102500      global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 100)          0           fc[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 4,121,240\n",
      "Trainable params: 4,093,120\n",
      "Non-trainable params: 28,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ShuffleNetV2(include_top=True, input_shape=(32, 32, 3), bottleneck_ratio=1, classes=100, L2=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:26:30.410929Z",
     "iopub.status.busy": "2023-11-21T01:26:30.410201Z",
     "iopub.status.idle": "2023-11-21T01:26:30.415945Z",
     "shell.execute_reply": "2023-11-21T01:26:30.415085Z",
     "shell.execute_reply.started": "2023-11-21T01:26:30.410893Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:26:33.941227Z",
     "iopub.status.busy": "2023-11-21T01:26:33.940555Z",
     "iopub.status.idle": "2023-11-21T01:26:33.945532Z",
     "shell.execute_reply": "2023-11-21T01:26:33.944739Z",
     "shell.execute_reply.started": "2023-11-21T01:26:33.941193Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_name = './L2'\n",
    "os.makedirs(exp_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:43:59.371765Z",
     "iopub.status.busy": "2023-11-21T01:43:59.371372Z",
     "iopub.status.idle": "2023-11-21T01:43:59.391446Z",
     "shell.execute_reply": "2023-11-21T01:43:59.390657Z",
     "shell.execute_reply.started": "2023-11-21T01:43:59.371732Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "num_epochs = 100\n",
    "optim = \"adam\"\n",
    "mcp_save = ModelCheckpoint(f'{exp_name}/shufflenetv2_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "rlronp = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, min_lr=0.000001)\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optim,\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T01:44:03.271135Z",
     "iopub.status.busy": "2023-11-21T01:44:03.270215Z",
     "iopub.status.idle": "2023-11-21T02:53:38.174170Z",
     "shell.execute_reply": "2023-11-21T02:53:38.172596Z",
     "shell.execute_reply.started": "2023-11-21T01:44:03.271099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:34:25.110242: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 13:34:25.442810: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/625 [..............................] - ETA: 1:01 - loss: 6.3648 - sparse_categorical_accuracy: 0.0234WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0678s vs `on_train_batch_end` time: 0.1302s). Check your callbacks.\n",
      "625/625 [==============================] - 139s 222ms/step - loss: 4.0146 - sparse_categorical_accuracy: 0.0993 - val_loss: 4.4596 - val_sparse_categorical_accuracy: 0.0389\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 142s 227ms/step - loss: 3.1801 - sparse_categorical_accuracy: 0.2265 - val_loss: 3.2361 - val_sparse_categorical_accuracy: 0.2204\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 142s 228ms/step - loss: 2.6920 - sparse_categorical_accuracy: 0.3199 - val_loss: 2.7600 - val_sparse_categorical_accuracy: 0.3098\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 2.2828 - sparse_categorical_accuracy: 0.4051 - val_loss: 3.2819 - val_sparse_categorical_accuracy: 0.2657\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 142s 227ms/step - loss: 1.9442 - sparse_categorical_accuracy: 0.4809 - val_loss: 2.4747 - val_sparse_categorical_accuracy: 0.3772\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 142s 227ms/step - loss: 1.6743 - sparse_categorical_accuracy: 0.5403 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.4159\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 1.4404 - sparse_categorical_accuracy: 0.5994 - val_loss: 2.3721 - val_sparse_categorical_accuracy: 0.4131\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.2177 - sparse_categorical_accuracy: 0.6544\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 1.2177 - sparse_categorical_accuracy: 0.6544 - val_loss: 2.6375 - val_sparse_categorical_accuracy: 0.4027\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 142s 227ms/step - loss: 0.6636 - sparse_categorical_accuracy: 0.8121 - val_loss: 1.9431 - val_sparse_categorical_accuracy: 0.5222\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.3571 - sparse_categorical_accuracy: 0.9098 - val_loss: 2.0533 - val_sparse_categorical_accuracy: 0.5218\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2148 - sparse_categorical_accuracy: 0.9513\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.2148 - sparse_categorical_accuracy: 0.9513 - val_loss: 2.2230 - val_sparse_categorical_accuracy: 0.5170\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9903 - val_loss: 2.1900 - val_sparse_categorical_accuracy: 0.5463\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0416 - sparse_categorical_accuracy: 0.9993\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0416 - sparse_categorical_accuracy: 0.9993 - val_loss: 2.2458 - val_sparse_categorical_accuracy: 0.5541\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0322 - sparse_categorical_accuracy: 0.9996 - val_loss: 2.2836 - val_sparse_categorical_accuracy: 0.5538\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0288 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0288 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.3193 - val_sparse_categorical_accuracy: 0.5552\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0269 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.3347 - val_sparse_categorical_accuracy: 0.5548\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0263 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0263 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.3530 - val_sparse_categorical_accuracy: 0.5581\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0252 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.3704 - val_sparse_categorical_accuracy: 0.5566\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0245 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0245 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.3882 - val_sparse_categorical_accuracy: 0.5574\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0241 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.3932 - val_sparse_categorical_accuracy: 0.5585\n",
      "Epoch 21/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0236 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0236 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4039 - val_sparse_categorical_accuracy: 0.5575\n",
      "Epoch 22/100\n",
      "625/625 [==============================] - 142s 226ms/step - loss: 0.0232 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4093 - val_sparse_categorical_accuracy: 0.5575\n",
      "Epoch 23/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0231 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4144 - val_sparse_categorical_accuracy: 0.5582\n",
      "Epoch 24/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0227 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4169 - val_sparse_categorical_accuracy: 0.5578\n",
      "Epoch 25/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0227 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0227 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4197 - val_sparse_categorical_accuracy: 0.5587\n",
      "Epoch 26/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0224 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4212 - val_sparse_categorical_accuracy: 0.5582\n",
      "Epoch 27/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0223 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0223 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4234 - val_sparse_categorical_accuracy: 0.5575\n",
      "Epoch 28/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4237 - val_sparse_categorical_accuracy: 0.5583\n",
      "Epoch 29/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4242 - val_sparse_categorical_accuracy: 0.5580\n",
      "Epoch 30/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4248 - val_sparse_categorical_accuracy: 0.5572\n",
      "Epoch 31/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4271 - val_sparse_categorical_accuracy: 0.5572\n",
      "Epoch 32/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4278 - val_sparse_categorical_accuracy: 0.5578\n",
      "Epoch 33/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4282 - val_sparse_categorical_accuracy: 0.5569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0220 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4305 - val_sparse_categorical_accuracy: 0.5571\n",
      "Epoch 35/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0220 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4304 - val_sparse_categorical_accuracy: 0.5581\n",
      "Epoch 36/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4307 - val_sparse_categorical_accuracy: 0.5583\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4330 - val_sparse_categorical_accuracy: 0.5574\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0220 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4338 - val_sparse_categorical_accuracy: 0.5576\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4340 - val_sparse_categorical_accuracy: 0.5577\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - 142s 226ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4351 - val_sparse_categorical_accuracy: 0.5569\n",
      "Epoch 41/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4371 - val_sparse_categorical_accuracy: 0.5571\n",
      "Epoch 42/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4352 - val_sparse_categorical_accuracy: 0.5572\n",
      "Epoch 43/100\n",
      "625/625 [==============================] - 142s 226ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4378 - val_sparse_categorical_accuracy: 0.5571\n",
      "Epoch 44/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4363 - val_sparse_categorical_accuracy: 0.5574\n",
      "Epoch 45/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4383 - val_sparse_categorical_accuracy: 0.5575\n",
      "Epoch 46/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4381 - val_sparse_categorical_accuracy: 0.5578\n",
      "Epoch 47/100\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 0.0216 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4411 - val_sparse_categorical_accuracy: 0.5581\n",
      "Epoch 48/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0216 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4417 - val_sparse_categorical_accuracy: 0.5570\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4410 - val_sparse_categorical_accuracy: 0.5570\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0215 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4411 - val_sparse_categorical_accuracy: 0.5578\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0215 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4426 - val_sparse_categorical_accuracy: 0.5573\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0215 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4427 - val_sparse_categorical_accuracy: 0.5578\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0215 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4426 - val_sparse_categorical_accuracy: 0.5566\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0214 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4439 - val_sparse_categorical_accuracy: 0.5578\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4444 - val_sparse_categorical_accuracy: 0.5573\n",
      "Epoch 56/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0214 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4454 - val_sparse_categorical_accuracy: 0.5562\n",
      "Epoch 57/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4455 - val_sparse_categorical_accuracy: 0.5567\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4461 - val_sparse_categorical_accuracy: 0.5573\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4455 - val_sparse_categorical_accuracy: 0.5571\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4462 - val_sparse_categorical_accuracy: 0.5568\n",
      "Epoch 61/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4482 - val_sparse_categorical_accuracy: 0.5569\n",
      "Epoch 62/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4479 - val_sparse_categorical_accuracy: 0.5571\n",
      "Epoch 63/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4502 - val_sparse_categorical_accuracy: 0.5577\n",
      "Epoch 64/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4490 - val_sparse_categorical_accuracy: 0.5577\n",
      "Epoch 65/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4515 - val_sparse_categorical_accuracy: 0.5565\n",
      "Epoch 66/100\n",
      "625/625 [==============================] - 142s 227ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4516 - val_sparse_categorical_accuracy: 0.5569\n",
      "Epoch 67/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4512 - val_sparse_categorical_accuracy: 0.5570\n",
      "Epoch 68/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4513 - val_sparse_categorical_accuracy: 0.5576\n",
      "Epoch 69/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4530 - val_sparse_categorical_accuracy: 0.5570\n",
      "Epoch 70/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4539 - val_sparse_categorical_accuracy: 0.5571\n",
      "Epoch 71/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0209 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4544 - val_sparse_categorical_accuracy: 0.5571\n",
      "Epoch 72/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0209 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4539 - val_sparse_categorical_accuracy: 0.5575\n",
      "Epoch 73/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0209 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4561 - val_sparse_categorical_accuracy: 0.5569\n",
      "Epoch 74/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0208 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4557 - val_sparse_categorical_accuracy: 0.5566\n",
      "Epoch 75/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0208 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4552 - val_sparse_categorical_accuracy: 0.5571\n",
      "Epoch 76/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0208 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4565 - val_sparse_categorical_accuracy: 0.5562\n",
      "Epoch 77/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0208 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4574 - val_sparse_categorical_accuracy: 0.5559\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0207 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4574 - val_sparse_categorical_accuracy: 0.5570\n",
      "Epoch 79/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0207 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4574 - val_sparse_categorical_accuracy: 0.5568\n",
      "Epoch 80/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0206 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4591 - val_sparse_categorical_accuracy: 0.5567\n",
      "Epoch 81/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0207 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4589 - val_sparse_categorical_accuracy: 0.5575\n",
      "Epoch 82/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0206 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4610 - val_sparse_categorical_accuracy: 0.5565\n",
      "Epoch 83/100\n",
      "625/625 [==============================] - 142s 226ms/step - loss: 0.0206 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4602 - val_sparse_categorical_accuracy: 0.5572\n",
      "Epoch 84/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0205 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4606 - val_sparse_categorical_accuracy: 0.5565\n",
      "Epoch 85/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0205 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4628 - val_sparse_categorical_accuracy: 0.5567\n",
      "Epoch 86/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0205 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4607 - val_sparse_categorical_accuracy: 0.5567\n",
      "Epoch 87/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0205 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4612 - val_sparse_categorical_accuracy: 0.5563\n",
      "Epoch 88/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0204 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4624 - val_sparse_categorical_accuracy: 0.5566\n",
      "Epoch 89/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0204 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4625 - val_sparse_categorical_accuracy: 0.5569\n",
      "Epoch 90/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0204 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4619 - val_sparse_categorical_accuracy: 0.5573\n",
      "Epoch 91/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4630 - val_sparse_categorical_accuracy: 0.5569\n",
      "Epoch 92/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.4650 - val_sparse_categorical_accuracy: 0.5564\n",
      "Epoch 93/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4647 - val_sparse_categorical_accuracy: 0.5565\n",
      "Epoch 94/100\n",
      "625/625 [==============================] - 142s 227ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4639 - val_sparse_categorical_accuracy: 0.5568\n",
      "Epoch 95/100\n",
      "625/625 [==============================] - 142s 226ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4657 - val_sparse_categorical_accuracy: 0.5567\n",
      "Epoch 96/100\n",
      "625/625 [==============================] - 142s 226ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4653 - val_sparse_categorical_accuracy: 0.5564\n",
      "Epoch 97/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4679 - val_sparse_categorical_accuracy: 0.5564\n",
      "Epoch 98/100\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9998 - val_loss: 2.4676 - val_sparse_categorical_accuracy: 0.5572\n",
      "Epoch 99/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0201 - sparse_categorical_accuracy: 0.9998"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    x=x_train,y=y_train,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val,y_val),\n",
    "    verbose=1,\n",
    "    callbacks=[mcp_save,rlronp],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['sparse_categorical_accuracy']\n",
    "val_acc=hist.history['val_sparse_categorical_accuracy']\n",
    "np.savez(os.path.join(exp_name, 'fit_history.npz'), train_loss=train_loss, val_loss=val_loss, train_acc=train_acc, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T03:01:35.270419Z",
     "iopub.status.busy": "2023-11-21T03:01:35.270058Z",
     "iopub.status.idle": "2023-11-21T03:01:35.277235Z",
     "shell.execute_reply": "2023-11-21T03:01:35.276344Z",
     "shell.execute_reply.started": "2023-11-21T03:01:35.270388Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss=model.history.history['loss']\n",
    "val_loss=model.history.history['val_loss']\n",
    "train_acc=model.history.history['sparse_categorical_accuracy']\n",
    "val_acc=model.history.history['val_sparse_categorical_accuracy']\n",
    "np.savez(os.path.join(exp_name, 'fit_history.npz'), train_loss=train_loss, val_loss=val_loss, train_acc=train_acc, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:53:58.007978Z",
     "iopub.status.busy": "2023-11-21T02:53:58.007409Z",
     "iopub.status.idle": "2023-11-21T02:55:11.103478Z",
     "shell.execute_reply": "2023-11-21T02:55:11.102729Z",
     "shell.execute_reply.started": "2023-11-21T02:53:58.007942Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:30:11.375589: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-11-22 19:30:11.398080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:37:00.0 name: Tesla P4 computeCapability: 6.1\n",
      "coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2023-11-22 19:30:11.398122: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 19:30:11.517226: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 19:30:11.549484: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-22 19:30:11.569986: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-22 19:30:11.659296: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-22 19:30:11.690950: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-22 19:30:11.895679: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-22 19:30:11.896548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-22 19:30:11.896965: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 19:30:11.908704: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600000000 Hz\n",
      "2023-11-22 19:30:11.909758: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cec10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 19:30:11.909777: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-22 19:30:11.996879: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4e8c410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 19:30:11.996913: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
      "2023-11-22 19:30:11.999911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:37:00.0 name: Tesla P4 computeCapability: 6.1\n",
      "coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2023-11-22 19:30:11.999943: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 19:30:11.999964: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 19:30:11.999977: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-22 19:30:11.999987: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-22 19:30:11.999998: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-22 19:30:12.000008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-11-22 19:30:12.000020: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-11-22 19:30:12.000494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-11-22 19:30:12.004550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-11-22 19:30:13.740488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-22 19:30:13.740516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-11-22 19:30:13.740523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-11-22 19:30:13.742411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6951 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:37:00.0, compute capability: 6.1)\n",
      "2023-11-22 19:30:17.585768: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-11-22 19:30:18.562640: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 53s 5ms/step - loss: 1.9193 - sparse_categorical_accuracy: 0.5254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9192873239517212, 0.5253999829292297]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_model = f'{exp_name}/shufflenetv2_model.hdf5'\n",
    "loaded_model_from_hdf5 = tf.keras.models.load_model(hdf5_model)\n",
    "loaded_model_from_hdf5.evaluate(x_test,y_test,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
